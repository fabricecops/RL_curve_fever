{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import universe # register the universe environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:04,397] Making new env: flashgames.CurveFever-v0\n",
      "[2018-10-17 21:49:04,419] Ports used: dict_keys([8888, 15901, 6006, 5901])\n",
      "[2018-10-17 21:49:04,421] [0] Creating container: image=quay.io/openai/universe.flashgames:0.20.28. Run the same thing by hand as: docker run -p 5900:5900 -p 15900:15900 --cap-add SYS_ADMIN --privileged --ipc host quay.io/openai/universe.flashgames:0.20.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:49:04,453] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 54 reward messages to agent: reward=2969.0 reward_min=30.0 reward_max=132.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:05,019] Remote closed: address=172.17.0.1:5900\n",
      "[2018-10-17 21:49:05,024] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | Setting VNC and rewarder password: openai\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:05 UTC 2018] Waiting for /tmp/.X11-unix/X0 to be created (try 1/10)\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Xvnc TigerVNC 1.7.0 - built Sep  8 2016 10:39:22\n",
      "universe-ZYrbHK-0 | [tigervnc] Copyright (C) 1999-2016 TigerVNC Team and many others (see README.txt)\n",
      "universe-ZYrbHK-0 | [tigervnc] See http://www.tigervnc.org for information on TigerVNC.\n",
      "universe-ZYrbHK-0 | [tigervnc] Underlying X server release 11400000, The X.Org Foundation\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension VNC-EXTENSION\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension Generic Event Extension\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension SHAPE\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension MIT-SHM\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XInputExtension\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XTEST\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension BIG-REQUESTS\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension SYNC\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XKEYBOARD\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XC-MISC\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XINERAMA\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XFIXES\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension RENDER\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension RANDR\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension COMPOSITE\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension DAMAGE\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension MIT-SCREEN-SAVER\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension DOUBLE-BUFFER\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension RECORD\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension DPMS\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension X-Resource\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XVideo\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension XVideo-MotionCompensation\n",
      "universe-ZYrbHK-0 | [tigervnc] Initializing built-in extension GLX\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:49:05 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  vncext:      VNC extension running!\n",
      "universe-ZYrbHK-0 | [tigervnc]  vncext:      Listening for VNC connections on all interface(s), port 5900\n",
      "universe-ZYrbHK-0 | [tigervnc]  vncext:      created VNC server for screen 0\n",
      "universe-ZYrbHK-0 | [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/Type1/, removing from list!\n",
      "universe-ZYrbHK-0 | [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/75dpi/, removing from list!\n",
      "universe-ZYrbHK-0 | [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/100dpi/, removing from list!\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:05 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for none\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:05,276] Launching system_diagnostics_logger.py, recorder_logdir=/tmp/demo\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:05,286] Launching reward_recorder.py, recorder_logdir=/tmp/demo\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:05,292] Launching vnc_recorder.py, recorder_logdir=/tmp/demo\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:05,304] PID 58 launched with command ['sudo', '-H', '-u', 'nobody', 'DISPLAY=:0', 'DBUS_SESSION_BUS_ADDRESS=/dev/null', '/app/universe-envs/controlplane/bin/controlplane.py', '--rewarder-port=15901']\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:05,353] init detected end of child process 61 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | WebSocket server settings:\n",
      "universe-ZYrbHK-0 |   - Listen on :5898\n",
      "universe-ZYrbHK-0 |   - Flash security policy server\n",
      "universe-ZYrbHK-0 |   - No SSL/TLS support (no cert file)\n",
      "universe-ZYrbHK-0 |   - proxying from :5898 to localhost:5900\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:05,467] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 40 reward messages to agent: reward=4425.0 reward_min=76.0 reward_max=188.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [reward_recorder] [2018-10-17 21:49:05,970] Listening on 0.0.0.0:15898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:06,026] Remote closed: address=172.17.0.1:5900\n",
      "[2018-10-17 21:49:06,029] Remote closed: address=172.17.0.1:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:49:06 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:06,033] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 172.17.0.1::44590\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:06 [error] 64#64: *1 connect() failed (111: Connection refused) while connecting to upstream, client: 172.17.0.1, server: , request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:15901/\", host: \"127.0.0.1:10003\"\n",
      "universe-ZYrbHK-0 | [nginx] 172.17.0.1 - openai [17/Oct/2018:21:49:06 +0000] \"GET / HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:06,109] init detected end of child process 18 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [vnc_recorder] [2018-10-17 21:49:06,111] Listening on 0.0.0.0:5899\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,376] [INFO:root] Starting play_controlplane.py with the following: command=['/app/universe-envs/controlplane/bin/controlplane.py', '--rewarder-port=15901'] args=Namespace(bot_demonstration=False, demonstration=False, env_id=None, idle_timeout=None, integrator_mode=False, no_env=False, no_rewarder=False, no_scorer=False, no_vexpect=False, remotes='vnc://127.0.0.1:5900', rewarder_fps=60, rewarder_port=15901, verbosity=0) env=environ({'TERM': 'xterm', 'MAIL': '/var/mail/nobody', 'SUDO_UID': '0', 'SUDO_USER': 'root', 'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin', 'HOSTNAME': '781b91809033', 'LOGNAME': 'nobody', 'SUDO_GID': '0', 'USER': 'nobody', 'USERNAME': 'nobody', 'HOME': '/nonexistent', 'SHELL': '/usr/sbin/nologin', 'DBUS_SESSION_BUS_ADDRESS': '/dev/null', 'DISPLAY': ':0', 'SUDO_COMMAND': '/app/universe-envs/controlplane/bin/controlplane.py --rewarder-port=15901'})\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,376] [INFO:root] [EnvStatus] Changing env_state: None (env_id=None) -> None (env_id=None) (episode_id: 0->0, fps=60)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,376] [INFO:universe.rewarder.remote] Starting Rewarder on port=15901\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,378] [INFO:universe.extra.universe.wrappers.logger] Running VNC environments with Logger set to print_frequency=5. To change this, pass \"print_frequency=k\" or \"print_frequency=None\" to \"env.configure\".\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,381] [INFO:universe.remotes.hardcoded_addresses] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,381] [INFO:universe.envs.vnc_env] Using the golang VNC implementation\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,381] [INFO:universe.envs.vnc_env] Using VNCSession arguments: {'start_timeout': 7, 'fine_quality_level': 50, 'compress_level': 9, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,381] [INFO:universe.envs.vnc_env] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,385] [INFO:universe.envs.vnc_env] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,386] [INFO:universe.extra.universe.envs.vnc_env] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,386] [INFO:root] [EnvStatus] Changing env_state: None (env_id=None) -> resetting (env_id=None) (episode_id: 0->1, fps=60)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,386] [INFO:root] [MainThread] Env state: env_id=None episode_id=1\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,386] [INFO:root] [MainThread] Writing None to /tmp/demo/env_id.txt\n",
      "universe-ZYrbHK-0 | 2018/10/17 21:49:06 I1017 21:49:06.388709 60 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 127.0.0.1::46436\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ZYrbHK-0 | 2018/10/17 21:49:06 I1017 21:49:06.402546 60 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:06 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for none\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,453] [INFO:gym_flashgames.launcher] [MainThread] Launching new Chrome process (attempt 0/10)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,454] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:06,542] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.07s, sent 45 reward messages to agent: reward=7806.0 reward_min=121.0 reward_max=331.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:06,644] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:06,813] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=50.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1760517.8 vnc_pixels_ps[total]=627151.8 reward_lag=None rewarder_message_lag=None fps=57.53\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:06,823] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"9.02ms\", \"calls\": 264, \"std\": \"3.70ms\"}, \"reward.parsing.gameover\": {\"mean\": \"284.03us\", \"calls\": 245, \"std\": \"213.46us\"}, \"rewarder.compute_reward\": {\"mean\": \"8.80ms\", \"calls\": 288, \"std\": \"6.17ms\"}, \"rewarder.frame\": {\"mean\": \"17.54ms\", \"calls\": 288, \"std\": \"2.94ms\"}, \"reward.parsing.score\": {\"mean\": \"9.66ms\", \"calls\": 245, \"std\": \"5.35ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"81.27us\", \"calls\": 245, \"std\": \"42.39us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"105.25us\", \"calls\": 242, \"std\": \"49.70us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.61ms\", \"calls\": 24, \"std\": \"6.16ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"62.50us\", \"calls\": 245, \"std\": \"26.73us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.36ms\", \"calls\": 242, \"std\": \"5.21ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"119.64us\", \"calls\": 288, \"std\": \"92.19us\"}} counters={\"agent_conn.reward\": {\"mean\": 78.50000000000004, \"calls\": 242, \"std\": 75.98516179674823}, \"reward.vnc.updates.n\": {\"mean\": 0.8749999999999998, \"calls\": 288, \"std\": 0.39816652969059774}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 147510.9959183674, \"calls\": 245, \"value\": 161431.0, \"std\": 5614.635907423927}} (export_time=109.20us)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:07,037] Using the golang VNC implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *1 client 172.17.0.1 closed keepalive connection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:07,039] Using VNCSession arguments: {'start_timeout': 7, 'subsample_level': 2, 'fine_quality_level': 50, 'encoding': 'tight'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:49:07 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: closed: 172.17.0.1::44590 (Clean disconnection)\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager: Framebuffer updates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:07,050] [0] Connecting to environment: vnc://172.17.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://172.17.0.1:15900/viewer/?password=openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:   Total: 0 rects, 0 pixels\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:          0 B (1:-nan ratio)\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 172.17.0.1::44630\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:07,062] [INFO:universe.rewarder.remote] Client connecting: peer=tcp4:127.0.0.1:53016 observer=False\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:07,064] [INFO:universe.rewarder.remote] WebSocket connection established\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *5 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *6 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *7 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *8 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *9 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *10 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *11 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *12 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *13 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:07 [info] 64#64: *14 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:07,187] [INFO:universe.rewarder.remote] CONNECTION STATUS: Marking connection as active: observer=False peer=tcp4:127.0.0.1:53016 total_conns=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:07,240] [0:172.17.0.1:5900] Sending reset for env_id=flashgames.CurveFever-v0 fps=60 episode_id=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:49:07,242] [INFO:universe.rewarder.remote] Received reset message: {'headers': {'episode_id': '0', 'message_id': 10, 'sent_at': 1539812947.2411985}, 'method': 'v0.env.reset', 'body': {'fps': 60, 'seed': None, 'env_id': 'flashgames.CurveFever-v0'}}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:07,562] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 44 reward messages to agent: reward=9359.0 reward_min=167.0 reward_max=578.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36882, 'rewarder.vnc.updates.pixels': 21640, 'rewarder.profile': '<2203 bytes>'}\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:08 [info] 64#64: *15 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:08 [info] 64#64: *16 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,150] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.51s\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,150] [INFO:gym_flashgames.launcher] [MainThread] Navigating browser to url=http://localhost\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:08 [info] 64#64: *17 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:08,575] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 40 reward messages to agent: reward=10490.0 reward_min=199.0 reward_max=635.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,596] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=None) -> running (env_id=None) (episode_id: 1->1, fps=60)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,597] [INFO:root] [MainThread] Writing None to /tmp/demo/env_id.txt\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,622] [INFO:root] [EnvStatus] Changing env_state: running (env_id=None) -> resetting (env_id=flashgames.CurveFever-v0) (episode_id: 1->2, fps=60)\n",
      "universe-ZYrbHK-0 | Manhole[1539812948.6230]: Patched <built-in function fork> and <built-in function fork>.\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,623] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "universe-ZYrbHK-0 | Manhole[1539812948.6256]: Manhole UDS path: /tmp/manhole-60\n",
      "universe-ZYrbHK-0 | Manhole[1539812948.6256]: Waiting for new connection (in pid:60) ...\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,639] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,656] init detected end of child process 118 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,680] [INFO:root] [EnvController] RESET CAUSE: changing out environments due to v0.env.reset (with episode_id=0): flashgames.CurveFever-v0 -> flashgames.CurveFever-v0 (new episode_id=2 fps=60)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,681] [INFO:root] [EnvController] Env state: env_id=flashgames.CurveFever-v0 episode_id=2\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:08,681] [INFO:root] [EnvController] Writing flashgames.CurveFever-v0 to /tmp/demo/env_id.txt\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,682] init detected end of child process 133 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,689] init detected end of child process 360 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,691] init detected end of child process 346 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,704] init detected end of child process 334 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:08 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:08 [info] 64#64: *19 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:08 [info] 64#64: *18 client 127.0.0.1 closed keepalive connection\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:08,869] Fetching files: git lfs pull -I git-lfs/flashgames.CurveFever-v0.tar.gz\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:08,870] If this hangs, your docker container may not be able to communicate with Github\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,902] init detected end of child process 121 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,907] init detected end of child process 129 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,907] init detected end of child process 130 with exit code 0, not killed by signal\n",
      "universe-ZYrbHK-0 | [init] [2018-10-17 21:49:08,909] init detected end of child process 132 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:09,577] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 46 reward messages to agent: reward=7966.0 reward_min=12.0 reward_max=453.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:10,589] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 51 reward messages to agent: reward=2373.0 reward_min=21.0 reward_max=95.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:11,595] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 49 reward messages to agent: reward=3726.0 reward_min=26.0 reward_max=182.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:11,838] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"9.54ms\", \"calls\": 223, \"std\": \"3.96ms\"}, \"reward.parsing.gameover\": {\"mean\": \"313.03us\", \"calls\": 228, \"std\": \"209.41us\"}, \"rewarder.compute_reward\": {\"mean\": \"10.23ms\", \"calls\": 273, \"std\": \"8.59ms\"}, \"rewarder.frame\": {\"mean\": \"18.46ms\", \"calls\": 273, \"std\": \"4.71ms\"}, \"reward.parsing.score\": {\"mean\": \"11.46ms\", \"calls\": 228, \"std\": \"7.83ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"92.91us\", \"calls\": 228, \"std\": \"60.69us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"116.15us\", \"calls\": 226, \"std\": \"75.03us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.87ms\", \"calls\": 50, \"std\": \"7.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"74.54us\", \"calls\": 228, \"std\": \"59.20us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"11.15ms\", \"calls\": 225, \"std\": \"7.60ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"134.64us\", \"calls\": 273, \"std\": \"109.65us\"}} counters={\"agent_conn.reward\": {\"mean\": 139.18222222222215, \"calls\": 225, \"std\": 124.56140068128055}, \"reward.vnc.updates.n\": {\"mean\": 0.8791208791208787, \"calls\": 273, \"std\": 0.4497180040076624}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 2, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 182121.13157894727, \"calls\": 228, \"value\": 192747.0, \"std\": 9440.086225632163}} (export_time=529.05us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:11,843] [INFO:universe.wrappers.logger] Stats for the past 5.03s: vnc_updates_ps=47.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1668177.6 vnc_pixels_ps[total]=596306.8 reward_lag=None rewarder_message_lag=None fps=54.50\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:12,610] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 37 reward messages to agent: reward=286.0 reward_min=1.0 reward_max=36.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2204 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,253] Finished running git lfs pull\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,253] git-lfs fetch succeeded\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,253] Unpacking files for flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,264] Merged 5 files from /tmp/flashgames.CurveFever-v0/public -> /app/universe-envs/flashgames/build/public/flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,264] Skipping merge for non-existent /tmp/flashgames.CurveFever-v0/private\n",
      "universe-ZYrbHK-0 | [unpack-lfs] [2018-10-17 21:49:13,265] Completed unpack for flashgames.CurveFever-v0 in 4.396s\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:13 UTC 2018] [/usr/local/bin/sudoable-env-setup] [debug] unpack-lfs completed with status code: 0. Created completion file: /usr/local/openai/git-lfs/flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [Wed Oct 17 21:49:13 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:13,369] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:13,370] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:13,517] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:13,616] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 27 reward messages to agent: reward=37.0 reward_min=1.0 reward_max=2.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:14,622] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 54 reward messages to agent: reward=508.0 reward_min=2.0 reward_max=22.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:14 [info] 64#64: *20 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:14 [info] 64#64: *21 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:49:14 [info] 64#64: *22 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:14,982] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.46s\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:14,986] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,020] [INFO:root] [EnvController] Skipping vexpect initialization since no macro present\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,021] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=flashgames.CurveFever-v0) -> running (env_id=flashgames.CurveFever-v0) (episode_id: 2->2, fps=60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-17 21:49:15,041] [0:172.17.0.1:5900] Initial reset complete: episode_id=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,022] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,023] [INFO:root] [Rewarder] Changing reward_parsers: None -> flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,023] [INFO:root] [Rewarder] Writing flashgames.CurveFever-v0 to /tmp/demo/env_id.txt\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,035] [ERROR:gym_controlplane.registration] No such vexpect path: /app/universe-envs/flashgames/gym_flashgames/../build/private/flashgames.CurveFever-v0/vexpect\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,035] [INFO:universe.rewarder.remote] Sending rewarder message: {'headers': {'parent_message_id': 10, 'parent_runtime': 7.793531894683838, 'message_id': 14, 'episode_id': '2', 'sent_at': 1539812955.0358026}, 'body': {}, 'method': 'v0.reply.env.reset'}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,036] [ERROR:gym_controlplane.registration] No scorer configuration found for flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,038] [ERROR:gym_controlplane.registration] No vexpect configuration found for flashgames.CurveFever-v0\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,039] [INFO:gym_controlplane.registration] Created reward parser for flashgames.CurveFever-v0: Reward<scorer=None vexpect=None>\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,039] [INFO:root] Using metadata_encoding={'x': 914, 'height': 100, 'type': 'qrcode', 'y': 658, 'width': 100} probe_key=96 subscription=[(914, 100, 658, 100)]\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,039] [INFO:universe.rewarder.remote] [Rewarder] Over past 6.44s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,039] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=0 episode_count=0 episode_duration=6.44\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,041] [INFO:universe.wrappers.logger] Stats for the past 8.65s: vnc_updates_ps=0.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=52982.7 vnc_pixels_ps[total]=193756.0 reward_lag=None rewarder_message_lag=None fps=0.35\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:15,044] [INFO:universe.pyprofile] [pyprofile] period=6.45s timers={\"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"std\": \"3.19ms\", \"mean\": \"4.56ms\", \"calls\": 11}, \"rewarder.frame\": {\"std\": \"4.49ms\", \"mean\": \"20.49ms\", \"calls\": 2}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"9.59ms\", \"mean\": \"5.66ms\", \"calls\": 3}, \"rewarder.sleep\": {\"std\": \"0.00us\", \"mean\": \"16.31ms\", \"calls\": 1}, \"rewarder.compute_reward\": {\"std\": \"9.04ms\", \"mean\": \"6.96ms\", \"calls\": 3}, \"rewarder.sleep.missed\": {\"std\": \"0.00us\", \"mean\": \"643.25us\", \"calls\": 1}} counters={\"control.env_id_change\": {\"std\": 0, \"mean\": 1.0, \"calls\": 1}, \"control.env_id_change.flashgames.CurveFever-v0\": {\"std\": 0, \"mean\": 1.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 3.7859388972001824, \"mean\": 4.333333333333333, \"calls\": 3}, \"rewarder_protocol.messages\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 11}, \"rewarder_protocol.messages.v0.control.ping\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 10}, \"rewarder_protocol.messages.v0.env.reset\": {\"std\": 0, \"mean\": 1.0, \"calls\": 1}} gauges={} (export_time=411.51us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:15,634] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 47 reward messages to agent: reward=1835.0 reward_min=1.0 reward_max=142.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:16,637] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 53 reward messages to agent: reward=1127.0 reward_min=6.0 reward_max=70.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36723, 'rewarder.vnc.updates.pixels': 20416}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:16,838] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"9.52ms\", \"calls\": 254, \"std\": \"3.77ms\"}, \"reward.parsing.gameover\": {\"mean\": \"319.11us\", \"calls\": 247, \"std\": \"366.85us\"}, \"rewarder.compute_reward\": {\"mean\": \"8.79ms\", \"calls\": 285, \"std\": \"6.96ms\"}, \"rewarder.frame\": {\"mean\": \"17.72ms\", \"calls\": 285, \"std\": \"3.63ms\"}, \"reward.parsing.score\": {\"mean\": \"9.33ms\", \"calls\": 247, \"std\": \"6.14ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"88.43us\", \"calls\": 247, \"std\": \"54.03us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"120.68us\", \"calls\": 245, \"std\": \"212.97us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.80ms\", \"calls\": 31, \"std\": \"7.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"86.37us\", \"calls\": 247, \"std\": \"248.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.59ms\", \"calls\": 229, \"std\": \"5.70ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"168.67us\", \"calls\": 285, \"std\": \"594.70us\"}} counters={\"agent_conn.reward\": {\"mean\": 18.668181818181814, \"calls\": 220, \"std\": 20.181457341416458}, \"reward.vnc.updates.n\": {\"mean\": 0.9087719298245616, \"calls\": 285, \"std\": 0.4095173652590663}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 2, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 18, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 193966.906882591, \"calls\": 247, \"value\": 196854.0, \"std\": 1275.4979975290144}} (export_time=132.80us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:16,848] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=51.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1795994.0 vnc_pixels_ps[total]=638171.4 reward_lag=None rewarder_message_lag=None fps=56.97\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:17,656] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 58 reward messages to agent: reward=3971.0 reward_min=39.0 reward_max=172.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2207 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:18,664] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 45 reward messages to agent: reward=1798.0 reward_min=2.0 reward_max=199.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:19,667] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 53 reward messages to agent: reward=3349.0 reward_min=32.0 reward_max=149.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36723, 'rewarder.vnc.updates.pixels': 20416}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:20,048] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=6.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=198158.6 vnc_pixels_ps[total]=424726.3 reward_lag=None rewarder_message_lag=None fps=60.16\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:20,050] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"718.97us\", \"mean\": \"16.85ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"768.23us\", \"mean\": \"16.06ms\", \"calls\": 300}, \"rewarder.compute_reward\": {\"std\": \"382.48us\", \"mean\": \"359.60us\", \"calls\": 301}, \"rewarder.sleep.missed\": {\"std\": \"0.00us\", \"mean\": \"5.30ms\", \"calls\": 1}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"220.25us\", \"mean\": \"146.12us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.2764271334961357, \"mean\": 0.08305647840531562, \"calls\": 301}} gauges={} (export_time=250.58us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:20,050] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<949 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:20,675] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 51 reward messages to agent: reward=6491.0 reward_min=86.0 reward_max=354.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:49:21,690] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 55 reward messages to agent: reward=9498.0 reward_min=142.0 reward_max=326.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:21,854] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"mean\": \"8.31ms\", \"calls\": 263, \"std\": \"3.18ms\"}, \"reward.parsing.gameover\": {\"mean\": \"259.68us\", \"calls\": 261, \"std\": \"128.09us\"}, \"rewarder.compute_reward\": {\"mean\": \"9.54ms\", \"calls\": 285, \"std\": \"6.44ms\"}, \"rewarder.frame\": {\"mean\": \"17.82ms\", \"calls\": 285, \"std\": \"3.96ms\"}, \"reward.parsing.score\": {\"mean\": \"9.77ms\", \"calls\": 261, \"std\": \"5.87ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"85.29us\", \"calls\": 261, \"std\": \"41.39us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"100.10us\", \"calls\": 260, \"std\": \"51.22us\"}, \"rewarder.sleep.missed\": {\"mean\": \"12.07ms\", \"calls\": 22, \"std\": \"8.11ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"59.81us\", \"calls\": 261, \"std\": \"30.82us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.38ms\", \"calls\": 260, \"std\": \"5.72ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"117.91us\", \"calls\": 285, \"std\": \"132.06us\"}} counters={\"agent_conn.reward\": {\"mean\": 101.21538461538464, \"calls\": 260, \"std\": 61.02350766932763}, \"reward.vnc.updates.n\": {\"mean\": 0.9438596491228063, \"calls\": 285, \"std\": 0.33092781640244534}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 1, \"std\": 0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 1, \"std\": 0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 206697.03065134102, \"calls\": 261, \"value\": 223170.0, \"std\": 7251.272788476703}} (export_time=113.96us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:21,864] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=53.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1892179.9 vnc_pixels_ps[total]=671529.4 reward_lag=None rewarder_message_lag=None fps=56.83\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:22 [info] 68#68: *54 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:22 [info] 68#68: *55 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:22 [info] 68#68: *56 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:22 [info] 68#68: *57 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:22,700] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 58 reward messages to agent: reward=12238.0 reward_min=184.0 reward_max=420.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36723, 'rewarder.vnc.updates.pixels': 20416, 'rewarder.profile': '<2167 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:23,715] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 54 reward messages to agent: reward=11488.0 reward_min=152.0 reward_max=459.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:24,744] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 51 reward messages to agent: reward=8407.0 reward_min=152.0 reward_max=306.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:25,063] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6175.7 vnc_pixels_ps[total]=45882.1 reward_lag=None rewarder_message_lag=None fps=60.05\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:25,063] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"25.90us\", \"mean\": \"16.75ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"519.85us\", \"mean\": \"16.19ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"299.87us\", \"mean\": \"303.60us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"231.59us\", \"mean\": \"129.09us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.2660985088079445, \"mean\": 0.07641196013289038, \"calls\": 301}} gauges={} (export_time=82.97us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:25,063] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<848 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:25,751] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 57 reward messages to agent: reward=9324.0 reward_min=152.0 reward_max=306.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36908, 'rewarder.vnc.updates.pixels': 21840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:26,766] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 56 reward messages to agent: reward=9477.0 reward_min=152.0 reward_max=459.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:26,865] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"8.77ms\", \"calls\": 290, \"std\": \"3.01ms\"}, \"reward.parsing.gameover\": {\"mean\": \"250.09us\", \"calls\": 271, \"std\": \"97.99us\"}, \"rewarder.compute_reward\": {\"mean\": \"8.06ms\", \"calls\": 297, \"std\": \"4.12ms\"}, \"rewarder.frame\": {\"mean\": \"16.97ms\", \"calls\": 297, \"std\": \"1.70ms\"}, \"reward.parsing.score\": {\"mean\": \"8.27ms\", \"calls\": 271, \"std\": \"3.38ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"70.10us\", \"calls\": 271, \"std\": \"22.72us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"95.91us\", \"calls\": 271, \"std\": \"39.60us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.80ms\", \"calls\": 7, \"std\": \"7.50ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"58.02us\", \"calls\": 271, \"std\": \"25.45us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"7.88ms\", \"calls\": 271, \"std\": \"3.31ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"91.28us\", \"calls\": 297, \"std\": \"48.62us\"}} counters={\"agent_conn.reward\": {\"mean\": 183.9926199261993, \"calls\": 271, \"std\": 59.54015094843488}, \"reward.vnc.updates.n\": {\"mean\": 0.9865319865319867, \"calls\": 297, \"std\": 0.4024675912171834}} gauges={\"reward_parser.score.last_score\": {\"mean\": 249764.8007380074, \"calls\": 271, \"value\": 273032.0, \"std\": 14222.215310749974}} (export_time=118.73us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:26,875] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=58.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=2077496.8 vnc_pixels_ps[total]=732171.9 reward_lag=None rewarder_message_lag=None fps=59.27\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:27,777] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 52 reward messages to agent: reward=9171.0 reward_min=152.0 reward_max=459.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<1945 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:28,792] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 55 reward messages to agent: reward=6064.0 reward_min=21.0 reward_max=305.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:29,794] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 49 reward messages to agent: reward=270.0 reward_min=1.0 reward_max=20.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:49:30,081] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6440.0 vnc_pixels_ps[total]=47845.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:30,082] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"145.81us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"384.21us\", \"mean\": \"16.12ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"327.60us\", \"mean\": \"358.93us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"162.93us\", \"mean\": \"141.01us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.27133238372607077, \"mean\": 0.07973421926910303, \"calls\": 301}} gauges={} (export_time=325.20us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:30,083] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:30,815] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 49 reward messages to agent: reward=216.0 reward_min=1.0 reward_max=15.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:31,822] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 53 reward messages to agent: reward=1483.0 reward_min=10.0 reward_max=47.0 done=False info={'rewarder.vnc.updates.n': 2, 'rewarder.vnc.updates.bytes': 71124, 'rewarder.vnc.updates.pixels': 23680}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:31,871] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"8.42ms\", \"calls\": 264, \"std\": \"3.08ms\"}, \"reward.parsing.gameover\": {\"mean\": \"274.84us\", \"calls\": 266, \"std\": \"180.16us\"}, \"rewarder.compute_reward\": {\"mean\": \"9.54ms\", \"calls\": 284, \"std\": \"6.74ms\"}, \"rewarder.frame\": {\"mean\": \"17.74ms\", \"calls\": 284, \"std\": \"4.11ms\"}, \"reward.parsing.score\": {\"mean\": \"9.52ms\", \"calls\": 266, \"std\": \"6.27ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"80.20us\", \"calls\": 266, \"std\": \"60.82us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"103.26us\", \"calls\": 266, \"std\": \"66.38us\"}, \"rewarder.sleep.missed\": {\"mean\": \"13.88ms\", \"calls\": 20, \"std\": \"8.09ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"64.89us\", \"calls\": 266, \"std\": \"48.43us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.39ms\", \"calls\": 258, \"std\": \"6.00ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"138.68us\", \"calls\": 284, \"std\": \"385.40us\"}} counters={\"agent_conn.reward\": {\"mean\": 65.2588235294118, \"calls\": 255, \"std\": 77.83722460393577}, \"reward.vnc.updates.n\": {\"mean\": 0.9577464788732393, \"calls\": 284, \"std\": 0.2881214760650272}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 8, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 285700.8157894735, \"calls\": 266, \"value\": 289625.0, \"std\": 4221.600906199235}} (export_time=273.23us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:31,887] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=54.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1920979.3 vnc_pixels_ps[total]=679783.6 reward_lag=None rewarder_message_lag=None fps=56.68\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:32,832] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 43 reward messages to agent: reward=4169.0 reward_min=0 reward_max=255.0 done=False info={'rewarder.vnc.updates.n': 2, 'rewarder.vnc.updates.bytes': 71124, 'rewarder.vnc.updates.pixels': 23680, 'rewarder.profile': '<2076 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:33,837] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 51 reward messages to agent: reward=5758.0 reward_min=93.0 reward_max=221.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:34,839] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 59 reward messages to agent: reward=7426.0 reward_min=115.0 reward_max=260.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36723, 'rewarder.vnc.updates.pixels': 20416}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:35,096] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6175.0 vnc_pixels_ps[total]=45876.3 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:35,096] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"427.34us\", \"mean\": \"16.80ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"736.10us\", \"mean\": \"16.04ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"395.21us\", \"mean\": \"383.08us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"313.20us\", \"mean\": \"162.18us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.2713323837260708, \"mean\": 0.07973421926910304, \"calls\": 301}} gauges={} (export_time=91.08us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:35,096] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:35,843] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.00s, sent 58 reward messages to agent: reward=8034.0 reward_min=131.0 reward_max=271.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:36,858] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 52 reward messages to agent: reward=7588.0 reward_min=141.0 reward_max=281.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:36,880] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"8.44ms\", \"calls\": 266, \"std\": \"2.84ms\"}, \"reward.parsing.gameover\": {\"mean\": \"287.04us\", \"calls\": 264, \"std\": \"216.06us\"}, \"rewarder.compute_reward\": {\"mean\": \"9.38ms\", \"calls\": 286, \"std\": \"6.00ms\"}, \"rewarder.frame\": {\"mean\": \"17.56ms\", \"calls\": 286, \"std\": \"3.46ms\"}, \"reward.parsing.score\": {\"mean\": \"9.48ms\", \"calls\": 264, \"std\": \"5.38ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"85.36us\", \"calls\": 264, \"std\": \"50.97us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"105.99us\", \"calls\": 261, \"std\": \"63.96us\"}, \"rewarder.sleep.missed\": {\"mean\": \"11.39ms\", \"calls\": 20, \"std\": \"7.34ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"67.76us\", \"calls\": 264, \"std\": \"88.73us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.16ms\", \"calls\": 261, \"std\": \"5.17ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"115.96us\", \"calls\": 286, \"std\": \"84.99us\"}} counters={\"agent_conn.reward\": {\"mean\": 125.67557251908394, \"calls\": 262, \"std\": 31.26744255979937}, \"reward.vnc.updates.n\": {\"mean\": 0.9685314685314689, \"calls\": 286, \"std\": 0.34901758472153444}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 304845.78030303045, \"calls\": 264, \"value\": 322600.0, \"std\": 9697.999523490984}} (export_time=466.35us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:36,902] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=55.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1942166.3 vnc_pixels_ps[total]=686126.8 reward_lag=None rewarder_message_lag=None fps=57.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:49:37,878] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 55 reward messages to agent: reward=8242.0 reward_min=0.0 reward_max=293.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36723, 'rewarder.vnc.updates.pixels': 20416, 'rewarder.profile': '<2205 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:38,909] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 50 reward messages to agent: reward=7475.0 reward_min=148.0 reward_max=151.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:39,924] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 44 reward messages to agent: reward=7995.0 reward_min=150.0 reward_max=454.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:40,098] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=21.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29154.6 vnc_pixels_ps[total]=216571.1 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:40,099] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.frame\": {\"std\": \"424.99us\", \"mean\": \"16.82ms\", \"calls\": 300}, \"rewarder.sleep\": {\"std\": \"748.40us\", \"mean\": \"15.91ms\", \"calls\": 300}, \"rewarder.compute_reward\": {\"std\": \"522.28us\", \"mean\": \"490.87us\", \"calls\": 300}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"237.55us\", \"mean\": \"183.38us\", \"calls\": 300}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.48080200557180797, \"mean\": 0.3599999999999999, \"calls\": 300}} gauges={} (export_time=121.59us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:40,099] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:40,961] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.04s, sent 43 reward messages to agent: reward=7735.0 reward_min=151.0 reward_max=304.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 36882, 'rewarder.vnc.updates.pixels': 21640}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:41,887] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"8.49ms\", \"calls\": 228, \"std\": \"4.19ms\"}, \"reward.parsing.gameover\": {\"mean\": \"344.09us\", \"calls\": 235, \"std\": \"306.07us\"}, \"rewarder.compute_reward\": {\"mean\": \"10.91ms\", \"calls\": 274, \"std\": \"8.11ms\"}, \"rewarder.frame\": {\"mean\": \"18.40ms\", \"calls\": 274, \"std\": \"4.47ms\"}, \"reward.parsing.score\": {\"mean\": \"11.88ms\", \"calls\": 235, \"std\": \"7.12ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"109.64us\", \"calls\": 235, \"std\": \"227.19us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"135.76us\", \"calls\": 232, \"std\": \"168.60us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.71ms\", \"calls\": 46, \"std\": \"6.54ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"79.96us\", \"calls\": 235, \"std\": \"73.03us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"11.53ms\", \"calls\": 232, \"std\": \"6.83ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"139.82us\", \"calls\": 274, \"std\": \"161.11us\"}} counters={\"agent_conn.reward\": {\"mean\": 170.40517241379314, \"calls\": 232, \"std\": 59.844890193075194}, \"reward.vnc.updates.n\": {\"mean\": 0.9197080291970803, \"calls\": 274, \"std\": 0.44571043279091627}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 3, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 341395.16595744714, \"calls\": 235, \"value\": 362134.0, \"std\": 11446.356462525906}} (export_time=128.51us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:41,913] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=50.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1759350.8 vnc_pixels_ps[total]=625829.0 reward_lag=None rewarder_message_lag=None fps=54.70\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:41,976] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 45 reward messages to agent: reward=8987.0 reward_min=152.0 reward_max=608.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2199 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:42,985] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 55 reward messages to agent: reward=12324.0 reward_min=182.0 reward_max=397.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:44,001] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 49 reward messages to agent: reward=6807.0 reward_min=30.0 reward_max=256.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:45,034] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.03s, sent 46 reward messages to agent: reward=391.0 reward_min=1.0 reward_max=55.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:45,113] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=21.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29201.9 vnc_pixels_ps[total]=216943.3 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:45,113] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"445.73us\", \"mean\": \"16.82ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"846.67us\", \"mean\": \"15.88ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"525.29us\", \"mean\": \"493.55us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"378.28us\", \"mean\": \"201.82us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4814154103704955, \"mean\": 0.362126245847176, \"calls\": 301}} gauges={} (export_time=79.39us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:45,113] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:46,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 47 reward messages to agent: reward=199.0 reward_min=1.0 reward_max=18.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:46,896] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"9.11ms\", \"calls\": 264, \"std\": \"3.27ms\"}, \"reward.parsing.gameover\": {\"mean\": \"279.54us\", \"calls\": 260, \"std\": \"232.97us\"}, \"rewarder.compute_reward\": {\"mean\": \"8.85ms\", \"calls\": 286, \"std\": \"6.56ms\"}, \"rewarder.frame\": {\"mean\": \"17.62ms\", \"calls\": 286, \"std\": \"3.66ms\"}, \"reward.parsing.score\": {\"mean\": \"9.08ms\", \"calls\": 260, \"std\": \"6.02ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"77.93us\", \"calls\": 260, \"std\": \"43.03us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"103.65us\", \"calls\": 259, \"std\": \"70.04us\"}, \"rewarder.sleep.missed\": {\"mean\": \"11.12ms\", \"calls\": 22, \"std\": \"7.97ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"65.77us\", \"calls\": 260, \"std\": \"89.50us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"8.89ms\", \"calls\": 254, \"std\": \"5.79ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"112.45us\", \"calls\": 286, \"std\": \"205.02us\"}} counters={\"agent_conn.reward\": {\"mean\": 87.78225806451613, \"calls\": 248, \"std\": 97.63300368546325}, \"reward.vnc.updates.n\": {\"mean\": 0.9545454545454543, \"calls\": 286, \"std\": 0.36710862157118834}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 1, \"std\": 0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 6, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 378894.61153846176, \"calls\": 260, \"value\": 383904.0, \"std\": 6046.463413745569}} (export_time=121.12us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:49:46,924] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=54.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1922220.3 vnc_pixels_ps[total]=680137.1 reward_lag=None rewarder_message_lag=None fps=57.09\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:47,064] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 55 reward messages to agent: reward=1599.0 reward_min=9.0 reward_max=96.0 done=False info={'rewarder.vnc.updates.n': 2, 'rewarder.vnc.updates.bytes': 71124, 'rewarder.vnc.updates.pixels': 23680, 'rewarder.profile': '<2182 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:48,072] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 46 reward messages to agent: reward=2904.0 reward_min=18.0 reward_max=144.0 done=False info={'rewarder.vnc.updates.n': 2, 'rewarder.vnc.updates.bytes': 72444, 'rewarder.vnc.updates.pixels': 33480}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:49,267] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.20s, sent 32 reward messages to agent: reward=178.0 reward_min=1.0 reward_max=27.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:50,131] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=21.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=28793.9 vnc_pixels_ps[total]=213892.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:50,133] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"46.90us\", \"mean\": \"16.76ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"285.68us\", \"mean\": \"16.14ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"300.01us\", \"mean\": \"352.33us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"109.39us\", \"mean\": \"122.75us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4814154103704956, \"mean\": 0.3621262458471762, \"calls\": 301}} gauges={} (export_time=295.88us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:50,134] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<854 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:50,287] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 41 reward messages to agent: reward=82.0 reward_min=1.0 reward_max=8.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:51,434] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.14s, sent 39 reward messages to agent: reward=162.0 reward_min=1.0 reward_max=10.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:51,901] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"9.40ms\", \"calls\": 245, \"std\": \"4.34ms\"}, \"reward.parsing.gameover\": {\"mean\": \"318.98us\", \"calls\": 249, \"std\": \"237.32us\"}, \"rewarder.compute_reward\": {\"mean\": \"9.37ms\", \"calls\": 280, \"std\": \"7.76ms\"}, \"rewarder.frame\": {\"mean\": \"17.95ms\", \"calls\": 280, \"std\": \"3.97ms\"}, \"reward.parsing.score\": {\"mean\": \"9.81ms\", \"calls\": 249, \"std\": \"7.31ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"103.65us\", \"calls\": 249, \"std\": \"179.21us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"117.05us\", \"calls\": 245, \"std\": \"78.08us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.60ms\", \"calls\": 35, \"std\": \"6.89ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"75.07us\", \"calls\": 249, \"std\": \"63.57us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"11.03ms\", \"calls\": 211, \"std\": \"6.52ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"121.08us\", \"calls\": 280, \"std\": \"89.32us\"}} counters={\"agent_conn.reward\": {\"mean\": 21.741379310344833, \"calls\": 174, \"std\": 32.26187661125076}, \"reward.vnc.updates.n\": {\"mean\": 0.9750000000000005, \"calls\": 280, \"std\": 0.44328926937620117}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 4, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 38, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 387145.05220883555, \"calls\": 249, \"value\": 387687.0, \"std\": 896.9654269266806}} (export_time=129.70us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:51,928] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=54.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1852029.9 vnc_pixels_ps[total]=658674.9 reward_lag=None rewarder_message_lag=None fps=55.97\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,357] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=0.00037073 match_time=230us\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,358] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,358] [INFO:universe.rewarder.remote] [Rewarder] Over past 2.92s, sent 30 reward messages to agent: reward=38.0 reward_min=0.0 reward_max=2.0 done=True info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2202 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,358] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,359] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,359] [INFO:root] [EnvStatus] Changing env_state: running (env_id=flashgames.DuskDrive-v0) -> resetting (env_id=flashgames.DuskDrive-v0) (episode_id: 5->6, fps=60)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,359] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,359] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,360] [INFO:root] [EnvController] Env state: env_id=flashgames.DuskDrive-v0 episode_id=6\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,360] [INFO:root] [EnvController] Writing flashgames.DuskDrive-v0 to /tmp/demo/env_id.txt\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,361] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,389] init detected end of child process 2011 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,393] init detected end of child process 2233 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,395] init detected end of child process 2026 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,398] init detected end of child process 2254 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,439] init detected end of child process 2267 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:49:54 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:49:54 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/flashgames.DuskDrive-v0 exists; not git-lfs pulling\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:49:54 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for flashgames.DuskDrive-v0\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,506] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,506] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,519] init detected end of child process 2025 with exit code 0, killed by SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,519] init detected end of child process 2014 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,520] init detected end of child process 2022 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:49:54,520] init detected end of child process 2023 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:54,668] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:55,147] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=21.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=28538.2 vnc_pixels_ps[total]=211991.9 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:55,149] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"196.63us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"444.55us\", \"mean\": \"16.09ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"235.18us\", \"mean\": \"364.67us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"80.59us\", \"mean\": \"136.29us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4784387677488621, \"mean\": 0.35215946843853807, \"calls\": 301}} gauges={} (export_time=233.41us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:49:55,149] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<854 bytes>'}\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:55 [info] 68#68: *71 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:55 [info] 68#68: *72 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:49:56 [info] 68#68: *73 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,050] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.38s\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,051] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/flashgames.DuskDrive-v0\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,076] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e flashgames.DuskDrive-v0 -r vnc://127.0.0.1:5900 -d\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,683] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,683] [play_vexpect] Using the golang VNC implementation\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,683] [play_vexpect] Using VNCSession arguments: {'compress_level': 0, 'start_timeout': 7, 'fine_quality_level': 50, 'subsample_level': 2, 'encoding': 'zrle'}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,683] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,687] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:56,687] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:49:56 I1017 21:49:56.688108 2774 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "universe-ds3ZS4-0 | [tigervnc] \n",
      "universe-ds3ZS4-0 | [tigervnc] Wed Oct 17 21:49:56 2018\n",
      "universe-ds3ZS4-0 | [tigervnc]  Connections: accepted: 127.0.0.1::47986\n",
      "universe-ds3ZS4-0 | [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "universe-ds3ZS4-0 | [tigervnc]  SConnection: Client requests security type VncAuth(2)\n",
      "universe-ds3ZS4-0 | [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ds3ZS4-0 | [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:49:56 I1017 21:49:56.69216 2774 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:49:57,120] [play_vexpect] Waiting for any of [MaskState<initializing0>] to activate\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:00,164] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26120.3 vnc_pixels_ps[total]=194028.1 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:00,166] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"398.16us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"582.25us\", \"mean\": \"15.88ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"320.39us\", \"mean\": \"514.94us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"195.11us\", \"mean\": \"209.24us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4705972737064394, \"mean\": 0.3289036544850497, \"calls\": 301}} gauges={} (export_time=326.63us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:00,166] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:04,223] [play_vexpect] Applying transition: ClickTransition<initializing0->['initializing1'] x=429 y=539 buttonmask=1> for active state MaskState<initializing0>. (Summary: plausible_states=MaskState<initializing0> distance_m=0.0489 match_time_m=703us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:04,237] [play_vexpect] Waiting for any of [MaskState<initializing1>] to activate (or whether any of [MaskState<initializing0>] are still active)\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:50:04 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 172.17.0.1::46338\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 172.17.0.1::46340\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: closed: 172.17.0.1::46340 (reading version failed: not an RFB\n",
      "universe-ZYrbHK-0 | [tigervnc]               client?)\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager: Framebuffer updates: 0\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:   Total: 0 rects, 0 pixels\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:          0 B (1:-nan ratio)\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:50:04 I1017 21:50:04.959133 61 gymvnc.go:374] [0:127.0.0.1:5900] update queue max of 60 reached; pausing further updates\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:05,179] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=18.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=24054.5 vnc_pixels_ps[total]=178650.7 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:05,180] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"383.92us\", \"mean\": \"16.83ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"578.40us\", \"mean\": \"15.74ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"250.62us\", \"mean\": \"609.23us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"144.21us\", \"mean\": \"239.22us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.460030332670297, \"mean\": 0.30232558139534876, \"calls\": 301}} gauges={} (export_time=160.69us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:50:05,181] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:08,238] [play_vexpect] Advancing to the next hopeful state (2/2): MaskState<initializing0>\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:09,871] [play_vexpect] Applying transition: ClickTransition<initializing1->['initializing2'] x=571 y=512 buttonmask=1> for active state MaskState<initializing1>. (Summary: plausible_states=[MaskState<initializing1>, MaskState<initializing0>] distance_m=[0.0365, 0.7533666666666666] match_time_m=['242us', '172us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:09,888] [play_vexpect] Waiting for any of [MaskState<initializing2>] to activate (or whether any of [MaskState<initializing1>] are still active)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:10,196] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26444.6 vnc_pixels_ps[total]=196447.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:10,197] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"138.58us\", \"mean\": \"16.79ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"414.71us\", \"mean\": \"15.91ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"290.16us\", \"mean\": \"496.48us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"121.51us\", \"mean\": \"184.36us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.46937200333997303, \"mean\": 0.3255813953488371, \"calls\": 301}} gauges={} (export_time=109.20us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:10,197] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:10,338] [play_vexpect] Applying transition: ClickTransition<initializing2->['ready0', 'ready1', 'ready2', 'ready3'] x=216 y=296 buttonmask=1> for active state MaskState<initializing2>. (Summary: plausible_states=[MaskState<initializing2>, MaskState<initializing1>] distance_m=[0.0359, 0.9961] match_time_m=['327us', '239us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:10,354] [play_vexpect] Waiting for any of [ready0, ready1, ready2, ready3] to activate (or whether any of [MaskState<initializing2>] are still active)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:10,738] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2, ready3, MaskState<initializing2>] distance_m=[0.31458586, 0.14552443, 0.30073458, 0.01057476, 0.9969] match_time_m=['195us', '148us', '66us', '59us', '149us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:10,739] [play_vexpect] Reaching start state: ready1\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:10,739] [play_vexpect] vexpect macro complete in 14.017237s\n",
      "universe-ds3ZS4-0 | [tigervnc] \n",
      "universe-ds3ZS4-0 | [tigervnc] Wed Oct 17 21:50:10 2018\n",
      "universe-ds3ZS4-0 | [tigervnc]  Connections: closed: 127.0.0.1::47986 (Clean disconnection)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager: Framebuffer updates: 206\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:   ZRLE:\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Solid: 46 rects, 2.02344 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:            4.37109 KiB (1:1808.38 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Bitmap RLE: 76 rects, 804.374 kpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                 106.31 KiB (1:29.5644 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Indexed RLE: 136 rects, 1.36472 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                  435.852 KiB (1:12.2348 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Full Colour: 218 rects, 8.73533 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                  25.0036 MiB (1:1.33281 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:   Total: 476 rects, 12.9279 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:          25.5373 MiB (1:1.93135 ratio)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,134] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=flashgames.DuskDrive-v0) -> running (env_id=flashgames.DuskDrive-v0) (episode_id: 6->6, fps=60)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,134] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,135] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=flashgames.DuskDrive-v0 episode_id=5->6, env_state=running\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,135] [INFO:universe.rewarder.remote] [Rewarder] Over past 16.78s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,136] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=387229.0 episode_count=3502 episode_duration=94.40\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:50:11 I1017 21:50:11.137435 61 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,137] [INFO:universe.wrappers.logger] Stats for the past 19.21s: vnc_updates_ps=3.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=111980.5 vnc_pixels_ps[total]=43373.9 reward_lag=None rewarder_message_lag=None fps=7.39\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,151] [INFO:universe.pyprofile] [pyprofile] period=19.25s timers={\"rewarder.sleep\": {\"mean\": \"12.67ms\", \"calls\": 131, \"std\": \"5.01ms\"}, \"reward.parsing.gameover\": {\"mean\": \"322.82us\", \"calls\": 64, \"std\": \"204.87us\"}, \"rewarder.compute_reward\": {\"mean\": \"5.44ms\", \"calls\": 144, \"std\": \"7.14ms\"}, \"rewarder.frame\": {\"mean\": \"17.22ms\", \"calls\": 144, \"std\": \"1.99ms\"}, \"reward.parsing.score\": {\"mean\": \"10.94ms\", \"calls\": 64, \"std\": \"6.43ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"112.49us\", \"calls\": 64, \"std\": \"131.19us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"127.07us\", \"calls\": 60, \"std\": \"82.72us\"}, \"rewarder.sleep.missed\": {\"mean\": \"5.78ms\", \"calls\": 12, \"std\": \"4.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"75.03us\", \"calls\": 64, \"std\": \"47.44us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"11.94ms\", \"calls\": 56, \"std\": \"5.19ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"139.20us\", \"calls\": 144, \"std\": \"101.80us\"}} counters={\"agent_conn.done\": {\"mean\": 1.0, \"calls\": 1, \"std\": 0}, \"agent_conn.reward\": {\"mean\": 1.3478260869565217, \"calls\": 23, \"std\": 0.6472807211834833}, \"reward.vnc.updates.n\": {\"mean\": 0.8958333333333333, \"calls\": 144, \"std\": 5.075263953313581}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 4, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 8, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 387711.32258064527, \"calls\": 62, \"value\": 387718.0, \"std\": 10.48460885004955}} (export_time=145.91us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:11,168] [INFO:gym_controlplane.reward.reward] First score parsed: score=566\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:12,149] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.01s, sent 53 reward messages to agent: reward=1444.0 reward_min=0 reward_max=52 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2284 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:13,165] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 55 reward messages to agent: reward=873.0 reward_min=4.0 reward_max=77.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:15,212] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=22.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=29788.9 vnc_pixels_ps[total]=221314.1 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:50:15,213] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"272.40us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"363.42us\", \"mean\": \"16.16ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"156.35us\", \"mean\": \"310.46us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"53.46us\", \"mean\": \"114.28us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.48416795087155734, \"mean\": 0.3720930232558136, \"calls\": 301}} gauges={} (export_time=75.34us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:15,213] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:50:15 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: closed: 172.17.0.1::46338 (Clean disconnection)\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager: Framebuffer updates: 0\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:   Total: 0 rects, 0 pixels\n",
      "universe-ZYrbHK-0 | [tigervnc]  EncodeManager:          0 B (1:-nan ratio)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:16,146] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=68.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1583808.0 vnc_pixels_ps[total]=664193.0 reward_lag=None rewarder_message_lag=None fps=59.15\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:16,191] [INFO:universe.pyprofile] [pyprofile] period=5.04s timers={\"rewarder.sleep\": {\"mean\": \"10.92ms\", \"calls\": 286, \"std\": \"4.20ms\"}, \"reward.parsing.gameover\": {\"mean\": \"258.00us\", \"calls\": 265, \"std\": \"234.17us\"}, \"rewarder.compute_reward\": {\"mean\": \"6.25ms\", \"calls\": 296, \"std\": \"6.04ms\"}, \"rewarder.frame\": {\"mean\": \"17.02ms\", \"calls\": 296, \"std\": \"2.15ms\"}, \"reward.parsing.score\": {\"mean\": \"6.33ms\", \"calls\": 265, \"std\": \"5.84ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"87.40us\", \"calls\": 265, \"std\": \"44.64us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"101.10us\", \"calls\": 200, \"std\": \"80.51us\"}, \"rewarder.sleep.missed\": {\"mean\": \"7.31ms\", \"calls\": 10, \"std\": \"9.68ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"81.92us\", \"calls\": 265, \"std\": \"185.83us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"8.98ms\", \"calls\": 175, \"std\": \"4.80ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"105.81us\", \"calls\": 296, \"std\": \"73.23us\"}} counters={\"agent_conn.reward\": {\"mean\": 16.583333333333332, \"calls\": 144, \"std\": 13.394759438660348}, \"reward.vnc.updates.n\": {\"mean\": 0.9628378378378379, \"calls\": 296, \"std\": 0.4141203305689826}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 65, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 90, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2520.5151515151524, \"calls\": 264, \"value\": 2954.0, \"std\": 702.358092075117}} (export_time=375.03us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:16,194] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.03s, sent 37 reward messages to agent: reward=71.0 reward_min=0.0 reward_max=5.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2201 bytes>'}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:20,230] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=28051.2 vnc_pixels_ps[total]=208384.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:20,230] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"522.57us\", \"mean\": \"16.80ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"578.81us\", \"mean\": \"16.05ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"205.50us\", \"mean\": \"381.98us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"75.24us\", \"mean\": \"140.97us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.47632777644084623, \"mean\": 0.34551495016611294, \"calls\": 301}} gauges={} (export_time=163.32us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:20,231] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:21,158] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=54.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=694357.3 vnc_pixels_ps[total]=270958.8 reward_lag=None rewarder_message_lag=None fps=58.27\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:21,192] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"13.92ms\", \"calls\": 278, \"std\": \"3.60ms\"}, \"reward.parsing.gameover\": {\"mean\": \"247.56us\", \"calls\": 254, \"std\": \"249.39us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.62ms\", \"calls\": 294, \"std\": \"6.09ms\"}, \"rewarder.frame\": {\"mean\": \"17.30ms\", \"calls\": 294, \"std\": \"3.16ms\"}, \"reward.parsing.score\": {\"mean\": \"3.43ms\", \"calls\": 254, \"std\": \"6.21ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"111.81us\", \"calls\": 254, \"std\": \"54.79us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"168.26us\", \"calls\": 63, \"std\": \"318.46us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.29ms\", \"calls\": 16, \"std\": \"10.37ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"97.70us\", \"calls\": 254, \"std\": \"74.47us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.02ms\", \"calls\": 63, \"std\": \"6.51ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"154.15us\", \"calls\": 294, \"std\": \"229.32us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9319727891156466, \"calls\": 294, \"std\": 0.4549292251984199}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 191, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 191, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 254, \"value\": 2954.0, \"std\": 0.0}} (export_time=187.16us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:21,193] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:50:21 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  Connections: accepted: 172.17.0.1::47846\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "universe-ZYrbHK-0 | [tigervnc]  SConnection: Client requests security type VeNCrypt(19)\n",
      "universe-ZYrbHK-0 | [tigervnc]  SVeNCrypt:   Client requests security type TLSVnc (258)\n",
      "universe-ZYrbHK-0 | [tigervnc] \n",
      "universe-ZYrbHK-0 | [tigervnc] Wed Oct 17 21:50:24 2018\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ZYrbHK-0 | [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:25,246] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26981.8 vnc_pixels_ps[total]=200439.3 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:25,247] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"196.93us\", \"mean\": \"16.79ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"340.32us\", \"mean\": \"16.04ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"181.48us\", \"mean\": \"395.34us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"77.39us\", \"mean\": \"148.68us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.47411396642173104, \"mean\": 0.3388704318936879, \"calls\": 301}} gauges={} (export_time=114.68us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:50:25,247] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:26,174] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=53.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=464053.6 vnc_pixels_ps[total]=195589.7 reward_lag=None rewarder_message_lag=None fps=59.03\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:26,212] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"mean\": \"14.64ms\", \"calls\": 288, \"std\": \"2.92ms\"}, \"reward.parsing.gameover\": {\"mean\": \"237.02us\", \"calls\": 253, \"std\": \"139.66us\"}, \"rewarder.compute_reward\": {\"mean\": \"2.49ms\", \"calls\": 295, \"std\": \"5.30ms\"}, \"rewarder.frame\": {\"mean\": \"17.07ms\", \"calls\": 295, \"std\": \"2.39ms\"}, \"reward.parsing.score\": {\"mean\": \"2.14ms\", \"calls\": 253, \"std\": \"5.52ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"121.99us\", \"calls\": 253, \"std\": \"55.85us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"150.60us\", \"calls\": 29, \"std\": \"64.25us\"}, \"rewarder.sleep.missed\": {\"mean\": \"11.66ms\", \"calls\": 7, \"std\": \"11.21ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"110.23us\", \"calls\": 253, \"std\": \"61.64us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"14.65ms\", \"calls\": 29, \"std\": \"8.34ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"148.51us\", \"calls\": 295, \"std\": \"103.30us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.8949152542372878, \"calls\": 295, \"std\": 0.41132924099121365}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 224, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 224, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 253, \"value\": 2954.0, \"std\": 0.0}} (export_time=168.56us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:26,213] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2125 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:30,263] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=21.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=28259.5 vnc_pixels_ps[total]=209921.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:30,264] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"179.06us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"368.68us\", \"mean\": \"16.06ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"296.90us\", \"mean\": \"394.38us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"253.47us\", \"mean\": \"160.07us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4773960376293313, \"mean\": 0.34883720930232526, \"calls\": 301}} gauges={} (export_time=158.31us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:30,264] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<850 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:31,178] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=57.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=622389.4 vnc_pixels_ps[total]=246791.9 reward_lag=None rewarder_message_lag=None fps=59.57\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:31,228] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"mean\": \"13.82ms\", \"calls\": 288, \"std\": \"4.02ms\"}, \"reward.parsing.gameover\": {\"mean\": \"242.03us\", \"calls\": 286, \"std\": \"123.51us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.22ms\", \"calls\": 300, \"std\": \"5.03ms\"}, \"rewarder.frame\": {\"mean\": \"16.91ms\", \"calls\": 300, \"std\": \"890.04us\"}, \"reward.parsing.score\": {\"mean\": \"2.65ms\", \"calls\": 286, \"std\": \"5.02ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"133.51us\", \"calls\": 286, \"std\": \"176.67us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"142.36us\", \"calls\": 49, \"std\": \"52.47us\"}, \"rewarder.sleep.missed\": {\"mean\": \"3.13ms\", \"calls\": 12, \"std\": \"3.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"107.17us\", \"calls\": 286, \"std\": \"53.43us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.63ms\", \"calls\": 49, \"std\": \"3.43ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"159.04us\", \"calls\": 300, \"std\": \"84.33us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9633333333333328, \"calls\": 300, \"std\": 0.23559975886407786}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 237, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 237, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 286, \"value\": 2954.0, \"std\": 0.0}} (export_time=169.99us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:31,229] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2131 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:35,281] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=27660.2 vnc_pixels_ps[total]=205459.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:35,283] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"46.23us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"344.44us\", \"mean\": \"16.02ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"344.18us\", \"mean\": \"439.60us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"196.43us\", \"mean\": \"170.34us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4763277764408462, \"mean\": 0.34551495016611294, \"calls\": 301}} gauges={} (export_time=308.28us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:35,284] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:36,189] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=53.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=534322.2 vnc_pixels_ps[total]=218565.3 reward_lag=None rewarder_message_lag=None fps=58.31\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:36,230] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"14.24ms\", \"calls\": 277, \"std\": \"3.26ms\"}, \"reward.parsing.gameover\": {\"mean\": \"272.89us\", \"calls\": 252, \"std\": \"184.77us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.41ms\", \"calls\": 289, \"std\": \"6.58ms\"}, \"rewarder.frame\": {\"mean\": \"17.29ms\", \"calls\": 289, \"std\": \"2.54ms\"}, \"reward.parsing.score\": {\"mean\": \"3.04ms\", \"calls\": 252, \"std\": \"6.70ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"136.52us\", \"calls\": 252, \"std\": \"67.04us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"159.54us\", \"calls\": 41, \"std\": \"89.49us\"}, \"rewarder.sleep.missed\": {\"mean\": \"11.81ms\", \"calls\": 12, \"std\": \"4.73ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"118.79us\", \"calls\": 252, \"std\": \"69.24us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"15.43ms\", \"calls\": 41, \"std\": \"8.14ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"169.85us\", \"calls\": 289, \"std\": \"140.89us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9134948096885818, \"calls\": 289, \"std\": 0.4032738000235908}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 211, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 211, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 252, \"value\": 2954.0, \"std\": 0.0}} (export_time=1.38ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:50:36,231] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2128 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:40,296] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26527.2 vnc_pixels_ps[total]=197010.1 reward_lag=None rewarder_message_lag=None fps=60.05\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:40,297] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"162.33us\", \"mean\": \"16.79ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"502.63us\", \"mean\": \"16.03ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"212.33us\", \"mean\": \"395.04us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"120.18us\", \"mean\": \"150.48us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4729680558328616, \"mean\": 0.33554817275747534, \"calls\": 301}} gauges={} (export_time=127.08us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:40,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<854 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:41,205] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=57.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=625823.2 vnc_pixels_ps[total]=248409.6 reward_lag=None rewarder_message_lag=None fps=58.62\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:41,238] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"13.86ms\", \"calls\": 289, \"std\": \"3.79ms\"}, \"reward.parsing.gameover\": {\"mean\": \"230.25us\", \"calls\": 278, \"std\": \"118.76us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.17ms\", \"calls\": 296, \"std\": \"5.52ms\"}, \"rewarder.frame\": {\"mean\": \"17.18ms\", \"calls\": 296, \"std\": \"2.87ms\"}, \"reward.parsing.score\": {\"mean\": \"2.66ms\", \"calls\": 278, \"std\": \"5.52ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"130.05us\", \"calls\": 278, \"std\": \"110.83us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"132.52us\", \"calls\": 50, \"std\": \"81.76us\"}, \"rewarder.sleep.missed\": {\"mean\": \"16.95ms\", \"calls\": 7, \"std\": \"8.92ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"102.12us\", \"calls\": 278, \"std\": \"53.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.19ms\", \"calls\": 50, \"std\": \"6.68ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"155.76us\", \"calls\": 296, \"std\": \"142.27us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9763513513513512, \"calls\": 296, \"std\": 0.3126402571183836}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 228, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 228, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 278, \"value\": 2954.0, \"std\": 0.0}} (export_time=168.56us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:41,239] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<2124 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:45,313] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26556.0 vnc_pixels_ps[total]=197177.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:45,314] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"88.35us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"207.97us\", \"mean\": \"16.09ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"145.64us\", \"mean\": \"371.77us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"66.64us\", \"mean\": \"140.52us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.47996400750992096, \"mean\": 0.3355481727574755, \"calls\": 301}} gauges={} (export_time=116.59us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:45,314] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:46,215] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=57.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=629865.6 vnc_pixels_ps[total]=249853.0 reward_lag=None rewarder_message_lag=None fps=59.69\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:46,249] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"13.59ms\", \"calls\": 293, \"std\": \"4.45ms\"}, \"reward.parsing.gameover\": {\"mean\": \"228.49us\", \"calls\": 284, \"std\": \"96.43us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.23ms\", \"calls\": 299, \"std\": \"5.09ms\"}, \"rewarder.frame\": {\"mean\": \"16.87ms\", \"calls\": 299, \"std\": \"720.74us\"}, \"reward.parsing.score\": {\"mean\": \"2.72ms\", \"calls\": 284, \"std\": \"5.09ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"116.38us\", \"calls\": 284, \"std\": \"34.39us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"138.73us\", \"calls\": 51, \"std\": \"29.55us\"}, \"rewarder.sleep.missed\": {\"mean\": \"4.46ms\", \"calls\": 6, \"std\": \"2.83ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"100.94us\", \"calls\": 284, \"std\": \"40.53us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.65ms\", \"calls\": 51, \"std\": \"3.23ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"137.24us\", \"calls\": 299, \"std\": \"54.42us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9732441471571908, \"calls\": 299, \"std\": 0.27038347846538}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 233, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 233, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 284, \"value\": 2954.0, \"std\": 0.0}} (export_time=197.17us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:46,250] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2123 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:50,330] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26531.1 vnc_pixels_ps[total]=197059.6 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:50,331] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"186.01us\", \"mean\": \"16.79ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"326.97us\", \"mean\": \"16.06ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"205.58us\", \"mean\": \"384.86us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"108.79us\", \"mean\": \"147.00us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.47179589032360775, \"mean\": 0.3322259136212625, \"calls\": 301}} gauges={} (export_time=187.87us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:50,331] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<853 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:50:51,225] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=54.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=703773.7 vnc_pixels_ps[total]=275199.5 reward_lag=None rewarder_message_lag=None fps=58.69\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:51,272] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"mean\": \"13.69ms\", \"calls\": 285, \"std\": \"3.84ms\"}, \"reward.parsing.gameover\": {\"mean\": \"237.42us\", \"calls\": 244, \"std\": \"151.69us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.60ms\", \"calls\": 294, \"std\": \"6.03ms\"}, \"rewarder.frame\": {\"mean\": \"17.16ms\", \"calls\": 294, \"std\": \"2.48ms\"}, \"reward.parsing.score\": {\"mean\": \"3.60ms\", \"calls\": 244, \"std\": \"6.29ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"109.90us\", \"calls\": 244, \"std\": \"52.46us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"126.76us\", \"calls\": 67, \"std\": \"57.30us\"}, \"rewarder.sleep.missed\": {\"mean\": \"12.20ms\", \"calls\": 9, \"std\": \"8.02ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"93.68us\", \"calls\": 244, \"std\": \"54.78us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"11.53ms\", \"calls\": 67, \"std\": \"6.69ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"140.38us\", \"calls\": 294, \"std\": \"138.07us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9319727891156464, \"calls\": 294, \"std\": 0.5180676085595496}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 177, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 177, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 244, \"value\": 2954.0, \"std\": 0.0}} (export_time=180.72us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:51,273] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2126 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:55,346] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25118.3 vnc_pixels_ps[total]=185723.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:55,347] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"146.37us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"332.49us\", \"mean\": \"16.07ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"221.48us\", \"mean\": \"372.12us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"160.09us\", \"mean\": \"142.23us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4741139664217309, \"mean\": 0.3388704318936877, \"calls\": 301}} gauges={} (export_time=140.91us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:50:55,348] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<850 bytes>'}\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:50:56 [info] 68#68: *75 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:50:56 [info] 68#68: *76 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:50:56 [info] 68#68: *77 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:50:56 [info] 68#68: *78 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:56,228] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=55.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=661295.2 vnc_pixels_ps[total]=261199.6 reward_lag=None rewarder_message_lag=None fps=58.38\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:56,278] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"13.87ms\", \"calls\": 283, \"std\": \"3.85ms\"}, \"reward.parsing.gameover\": {\"mean\": \"230.30us\", \"calls\": 258, \"std\": \"180.87us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.49ms\", \"calls\": 293, \"std\": \"6.26ms\"}, \"rewarder.frame\": {\"mean\": \"17.23ms\", \"calls\": 293, \"std\": \"2.59ms\"}, \"reward.parsing.score\": {\"mean\": \"3.27ms\", \"calls\": 258, \"std\": \"6.38ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"107.75us\", \"calls\": 258, \"std\": \"51.36us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"153.09us\", \"calls\": 58, \"std\": \"171.39us\"}, \"rewarder.sleep.missed\": {\"mean\": \"13.56ms\", \"calls\": 10, \"std\": \"4.78ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"93.46us\", \"calls\": 258, \"std\": \"59.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.70ms\", \"calls\": 58, \"std\": \"7.12ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"132.09us\", \"calls\": 293, \"std\": \"101.79us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9488054607508536, \"calls\": 293, \"std\": 0.43095975208281756}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 200, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 200, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 258, \"value\": 2954.0, \"std\": 0.0}} (export_time=139.95us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:50:56,278] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2129 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:00,364] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5158.5 vnc_pixels_ps[total]=40198.8 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:00,364] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"37.42us\", \"mean\": \"16.77ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"340.21us\", \"mean\": \"15.97ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"281.57us\", \"mean\": \"471.09us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"168.82us\", \"mean\": \"184.65us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.25517891580177127, \"mean\": 0.06976744186046514, \"calls\": 301}} gauges={} (export_time=198.13us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:00,365] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:01,242] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=50.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=586544.2 vnc_pixels_ps[total]=235957.9 reward_lag=None rewarder_message_lag=None fps=58.46\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:01,291] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"13.94ms\", \"calls\": 280, \"std\": \"3.38ms\"}, \"reward.parsing.gameover\": {\"mean\": \"294.22us\", \"calls\": 252, \"std\": \"192.32us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.55ms\", \"calls\": 293, \"std\": \"6.06ms\"}, \"rewarder.frame\": {\"mean\": \"17.22ms\", \"calls\": 293, \"std\": \"2.39ms\"}, \"reward.parsing.score\": {\"mean\": \"3.19ms\", \"calls\": 252, \"std\": \"6.29ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"147.99us\", \"calls\": 252, \"std\": \"92.25us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"147.15us\", \"calls\": 50, \"std\": \"73.39us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.95ms\", \"calls\": 13, \"std\": \"6.23ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"130.50us\", \"calls\": 252, \"std\": \"87.05us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"13.28ms\", \"calls\": 50, \"std\": \"7.34ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"186.15us\", \"calls\": 293, \"std\": \"125.55us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.8634812286689421, \"calls\": 293, \"std\": 0.3537434308735024}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 202, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 202, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 252, \"value\": 2954.0, \"std\": 0.0}} (export_time=271.08us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:51:01,292] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:05,379] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5934.4 vnc_pixels_ps[total]=44013.4 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:05,380] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"409.15us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"569.33us\", \"mean\": \"15.93ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"302.94us\", \"mean\": \"469.29us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"233.56us\", \"mean\": \"187.93us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.27133238372607077, \"mean\": 0.07973421926910307, \"calls\": 301}} gauges={} (export_time=91.55us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:05,380] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<847 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:06,248] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=51.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=618724.7 vnc_pixels_ps[total]=247557.0 reward_lag=None rewarder_message_lag=None fps=57.76\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:06,296] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"14.17ms\", \"calls\": 263, \"std\": \"3.29ms\"}, \"reward.parsing.gameover\": {\"mean\": \"287.69us\", \"calls\": 237, \"std\": \"205.25us\"}, \"rewarder.compute_reward\": {\"mean\": \"4.22ms\", \"calls\": 288, \"std\": \"7.21ms\"}, \"rewarder.frame\": {\"mean\": \"17.46ms\", \"calls\": 288, \"std\": \"2.92ms\"}, \"reward.parsing.score\": {\"mean\": \"4.18ms\", \"calls\": 237, \"std\": \"7.53ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"135.26us\", \"calls\": 237, \"std\": \"74.70us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"175.05us\", \"calls\": 57, \"std\": \"185.13us\"}, \"rewarder.sleep.missed\": {\"mean\": \"7.82ms\", \"calls\": 25, \"std\": \"6.70ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"117.93us\", \"calls\": 237, \"std\": \"67.21us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"15.13ms\", \"calls\": 57, \"std\": \"7.51ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"203.08us\", \"calls\": 288, \"std\": \"573.94us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.8854166666666664, \"calls\": 288, \"std\": 0.4767001482681591}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 180, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 180, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 237, \"value\": 2954.0, \"std\": 0.0}} (export_time=268.46us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:06,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:10,396] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6378.2 vnc_pixels_ps[total]=47311.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:10,397] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"247.72us\", \"mean\": \"16.80ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"551.63us\", \"mean\": \"15.93ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"446.23us\", \"mean\": \"489.85us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"292.71us\", \"mean\": \"197.45us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.2660985088079445, \"mean\": 0.07641196013289046, \"calls\": 301}} gauges={} (export_time=139.00us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:10,397] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:11,262] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=51.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=662850.1 vnc_pixels_ps[total]=262324.7 reward_lag=None rewarder_message_lag=None fps=57.25\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:11,297] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"13.72ms\", \"calls\": 264, \"std\": \"4.07ms\"}, \"reward.parsing.gameover\": {\"mean\": \"290.22us\", \"calls\": 235, \"std\": \"255.86us\"}, \"rewarder.compute_reward\": {\"mean\": \"4.54ms\", \"calls\": 287, \"std\": \"7.80ms\"}, \"rewarder.frame\": {\"mean\": \"17.58ms\", \"calls\": 287, \"std\": \"3.56ms\"}, \"reward.parsing.score\": {\"mean\": \"4.63ms\", \"calls\": 235, \"std\": \"8.19ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"129.43us\", \"calls\": 235, \"std\": \"59.04us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"144.72us\", \"calls\": 62, \"std\": \"58.09us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.80ms\", \"calls\": 23, \"std\": \"8.61ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"125.84us\", \"calls\": 235, \"std\": \"199.71us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"15.60ms\", \"calls\": 62, \"std\": \"8.37ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"175.42us\", \"calls\": 287, \"std\": \"171.33us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.8954703832752611, \"calls\": 287, \"std\": 0.4977716480779837}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 173, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 173, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 235, \"value\": 2954.0, \"std\": 0.0}} (export_time=226.97us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:11,297] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:15,413] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6172.5 vnc_pixels_ps[total]=45858.1 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:15,414] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"371.84us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"483.78us\", \"mean\": \"16.00ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"247.80us\", \"mean\": \"421.13us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"79.84us\", \"mean\": \"157.37us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.27133238372607077, \"mean\": 0.07973421926910307, \"calls\": 301}} gauges={} (export_time=123.02us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:15,414] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<851 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:51:16,277] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=56.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=603397.2 vnc_pixels_ps[total]=239440.1 reward_lag=None rewarder_message_lag=None fps=59.64\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:16,314] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep\": {\"mean\": \"13.72ms\", \"calls\": 291, \"std\": \"4.14ms\"}, \"reward.parsing.gameover\": {\"mean\": \"249.73us\", \"calls\": 269, \"std\": \"121.07us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.18ms\", \"calls\": 299, \"std\": \"5.03ms\"}, \"rewarder.frame\": {\"mean\": \"16.91ms\", \"calls\": 299, \"std\": \"1.01ms\"}, \"reward.parsing.score\": {\"mean\": \"2.76ms\", \"calls\": 269, \"std\": \"5.13ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"126.32us\", \"calls\": 269, \"std\": \"71.14us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"148.17us\", \"calls\": 48, \"std\": \"116.91us\"}, \"rewarder.sleep.missed\": {\"mean\": \"3.91ms\", \"calls\": 8, \"std\": \"4.61ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"110.50us\", \"calls\": 269, \"std\": \"54.75us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.77ms\", \"calls\": 48, \"std\": \"3.45ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"151.49us\", \"calls\": 299, \"std\": \"81.52us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9464882943143805, \"calls\": 299, \"std\": 0.3804969053707867}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 221, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 221, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 269, \"value\": 2954.0, \"std\": 0.0}} (export_time=482.80us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:16,315] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2131 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:20,430] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25674.2 vnc_pixels_ps[total]=190655.7 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:20,430] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"387.04us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"515.09us\", \"mean\": \"16.04ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"232.30us\", \"mean\": \"384.54us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"154.69us\", \"mean\": \"150.63us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4751872044691979, \"mean\": 0.32225913621262425, \"calls\": 301}} gauges={} (export_time=115.39us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:20,431] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<853 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:21,292] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=55.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=593294.6 vnc_pixels_ps[total]=238240.5 reward_lag=None rewarder_message_lag=None fps=59.44\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:21,326] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"14.00ms\", \"calls\": 293, \"std\": \"3.49ms\"}, \"reward.parsing.gameover\": {\"mean\": \"226.12us\", \"calls\": 270, \"std\": \"142.36us\"}, \"rewarder.compute_reward\": {\"mean\": \"2.79ms\", \"calls\": 298, \"std\": \"4.73ms\"}, \"rewarder.frame\": {\"mean\": \"16.99ms\", \"calls\": 298, \"std\": \"1.69ms\"}, \"reward.parsing.score\": {\"mean\": \"2.36ms\", \"calls\": 270, \"std\": \"4.82ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"120.22us\", \"calls\": 270, \"std\": \"64.60us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"115.94us\", \"calls\": 47, \"std\": \"49.63us\"}, \"rewarder.sleep.missed\": {\"mean\": \"9.69ms\", \"calls\": 5, \"std\": \"9.62ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"101.35us\", \"calls\": 270, \"std\": \"63.30us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"10.98ms\", \"calls\": 47, \"std\": \"5.61ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"154.07us\", \"calls\": 298, \"std\": \"222.28us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.936241610738255, \"calls\": 298, \"std\": 0.3471315385614844}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 223, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 223, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 270, \"value\": 2954.0, \"std\": 0.0}} (export_time=280.86us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:21,327] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2128 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:25,446] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=18.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=23948.9 vnc_pixels_ps[total]=177675.5 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:25,447] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"91.64us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"277.66us\", \"mean\": \"16.02ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"196.37us\", \"mean\": \"421.09us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"120.02us\", \"mean\": \"165.67us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4614484394133194, \"mean\": 0.30564784053156135, \"calls\": 301}} gauges={} (export_time=130.41us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:25,447] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:26,297] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=35.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=480981.4 vnc_pixels_ps[total]=200839.0 reward_lag=None rewarder_message_lag=None fps=58.77\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:26,333] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"14.49ms\", \"calls\": 271, \"std\": \"3.34ms\"}, \"reward.parsing.gameover\": {\"mean\": \"295.98us\", \"calls\": 169, \"std\": \"180.02us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.44ms\", \"calls\": 292, \"std\": \"6.50ms\"}, \"rewarder.frame\": {\"mean\": \"17.17ms\", \"calls\": 292, \"std\": \"2.01ms\"}, \"reward.parsing.score\": {\"mean\": \"4.77ms\", \"calls\": 169, \"std\": \"7.69ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"138.34us\", \"calls\": 169, \"std\": \"114.12us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"166.30us\", \"calls\": 49, \"std\": \"181.94us\"}, \"rewarder.sleep.missed\": {\"mean\": \"4.91ms\", \"calls\": 21, \"std\": \"5.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"113.89us\", \"calls\": 169, \"std\": \"52.06us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"14.62ms\", \"calls\": 49, \"std\": \"7.01ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"189.25us\", \"calls\": 292, \"std\": \"278.84us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.6027397260273969, \"calls\": 292, \"std\": 0.5370077725994539}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 120, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 120, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 169, \"value\": 2954.0, \"std\": 0.0}} (export_time=226.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:51:26,334] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2132 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,043] [INFO:universe.utils] [gameover] Gameover screen detected: distance_n=0.00037073 match_time=274us\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,043] [INFO:gym_controlplane.reward.reward] RESET CAUSE: gameover state reached\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,043] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.71s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=True info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,043] [INFO:root] [Rewarder] Resetting environment since done=True\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,044] [INFO:root] [Rewarder] Triggering a reset on EnvController\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,044] [INFO:root] [EnvStatus] Changing env_state: running (env_id=flashgames.DuskDrive-v0) -> resetting (env_id=flashgames.DuskDrive-v0) (episode_id: 6->7, fps=60)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,044] [INFO:root] [Rewarder] Blocking until env finishes resetting\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,044] [INFO:root] [EnvController] controlplane.py is resetting the environment\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,044] [INFO:root] [EnvController] Env state: env_id=flashgames.DuskDrive-v0 episode_id=7\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,045] [INFO:root] [EnvController] Writing flashgames.DuskDrive-v0 to /tmp/demo/env_id.txt\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,046] [ERROR:root] Closing server (via subprocess.close()) and all chromes (via pkill chromedriver || :; pkill chrome || :)\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,087] init detected end of child process 2529 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,108] init detected end of child process 2544 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,109] init detected end of child process 2750 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,109] init detected end of child process 2771 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:51:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Allowing outbound network traffic to non-private IPs for git-lfs. (Going to fetch files via git lfs.)\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,162] init detected end of child process 2784 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:51:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Completion file /usr/local/openai/git-lfs/flashgames.DuskDrive-v0 exists; not git-lfs pulling\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,231] init detected end of child process 2540 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,231] init detected end of child process 2532 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,231] init detected end of child process 2541 with exit code 0, not killed by signal\n",
      "universe-ds3ZS4-0 | [init] [2018-10-17 21:51:28,231] init detected end of child process 2543 with exit code 0, killed by SIGTERM: 15\n",
      "universe-ds3ZS4-0 | [Wed Oct 17 21:51:28 UTC 2018] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for flashgames.DuskDrive-v0\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,251] [INFO:gym_flashgames.launcher] [EnvController] Launching new Chrome process (attempt 0/10)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,252] [INFO:root] Replacing selenium_wrapper_server since we currently do it at every episode boundary\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:28,409] [selenium_wrapper_server] Calling webdriver.Chrome()\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:51:29 [info] 68#68: *82 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:51:29 [info] 68#68: *83 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [nginx] 2018/10/17 21:51:29 [info] 68#68: *84 client sent invalid request while reading client request line, client: 127.0.0.1, server: , request: \"CONNECT www.google.com:443 HTTP/1.1\"\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:29,983] [selenium_wrapper_server] Call to webdriver.Chrome() completed: 1.57s\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:29,984] [INFO:gym_flashgames.launcher] [EnvController] Navigating browser to url=http://localhost/flashgames.DuskDrive-v0\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,027] [INFO:root] [EnvController] Running command: /app/universe-envs/controlplane/bin/play_vexpect -e flashgames.DuskDrive-v0 -r vnc://127.0.0.1:5900 -d\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:30,462] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=16.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=20548.8 vnc_pixels_ps[total]=152379.9 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:30,463] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"290.80us\", \"mean\": \"16.82ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"793.83us\", \"mean\": \"15.96ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"634.94us\", \"mean\": \"447.81us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"581.89us\", \"mean\": \"189.72us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4442321382914904, \"mean\": 0.2691029900332228, \"calls\": 301}} gauges={} (export_time=74.63us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:30,463] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<848 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,803] [play_vexpect] No rewarder addresses were provided, so this env cannot connect to the remote's rewarder channel, and cannot send control messages (e.g. reset)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,803] [play_vexpect] Using the golang VNC implementation\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,803] [play_vexpect] Using VNCSession arguments: {'encoding': 'zrle', 'compress_level': 0, 'fine_quality_level': 50, 'start_timeout': 7, 'subsample_level': 2}. (Customize by running \"env.configure(vnc_kwargs={...})\"\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,803] [play_vexpect] Printed stats will ignore clock skew. (This usually makes sense only when the environment and agent are on the same machine.)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,807] [play_vexpect] [0] Connecting to environment: vnc://127.0.0.1:5900 password=openai. If desired, you can manually connect a VNC viewer, such as TurboVNC. Most environments provide a convenient in-browser VNC client: http://None/viewer/?password=openai\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:30,808] [play_vexpect] [0] Connecting to environment details: vnc_address=127.0.0.1:5900 vnc_password=openai rewarder_address=None rewarder_password=openai\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:51:30 I1017 21:51:30.808321 3290 gymvnc.go:417] [0:127.0.0.1:5900] opening connection to VNC server\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:51:30 I1017 21:51:30.810094 3290 gymvnc.go:550] [0:127.0.0.1:5900] connection established\n",
      "universe-ds3ZS4-0 | [tigervnc] \n",
      "universe-ds3ZS4-0 | [tigervnc] Wed Oct 17 21:51:30 2018\n",
      "universe-ds3ZS4-0 | [tigervnc]  Connections: accepted: 127.0.0.1::50596\n",
      "universe-ds3ZS4-0 | [tigervnc]  SConnection: Client needs protocol version 3.8\n",
      "universe-ds3ZS4-0 | [tigervnc]  SConnection: Client requests security type VncAuth(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [tigervnc]  VNCSConnST:  Server default pixel format depth 24 (32bpp) little-endian rgb888\n",
      "universe-ds3ZS4-0 | [tigervnc]  VNCSConnST:  Client pixel format depth 24 (32bpp) little-endian bgr888\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:31,273] [play_vexpect] Waiting for any of [MaskState<initializing0>] to activate\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:35,480] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=17.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=22472.4 vnc_pixels_ps[total]=166723.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:35,481] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"213.30us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"389.40us\", \"mean\": \"15.89ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"277.78us\", \"mean\": \"505.88us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"76.58us\", \"mean\": \"187.90us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.45406982061501894, \"mean\": 0.2890365448504984, \"calls\": 301}} gauges={} (export_time=181.44us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:35,482] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<849 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:38,362] [play_vexpect] Applying transition: ClickTransition<initializing0->['initializing1'] x=429 y=539 buttonmask=1> for active state MaskState<initializing0>. (Summary: plausible_states=MaskState<initializing0> distance_m=0.0489 match_time_m=707us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:38,373] [play_vexpect] Waiting for any of [MaskState<initializing1>] to activate (or whether any of [MaskState<initializing0>] are still active)\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:51:39 I1017 21:51:39.125784 61 gymvnc.go:374] [0:127.0.0.1:5900] update queue max of 60 reached; pausing further updates\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:40,497] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=15.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=19497.8 vnc_pixels_ps[total]=144661.4 reward_lag=None rewarder_message_lag=None fps=60.02\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:40,498] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"198.95us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"446.34us\", \"mean\": \"15.83ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"348.10us\", \"mean\": \"560.58us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"257.07us\", \"mean\": \"225.97us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.43325239895009615, \"mean\": 0.24916943521594673, \"calls\": 301}} gauges={} (export_time=263.21us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:40,499] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<848 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:42,423] [play_vexpect] Advancing to the next hopeful state (2/2): MaskState<initializing0>\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:43,556] [play_vexpect] Applying transition: ClickTransition<initializing1->['initializing2'] x=571 y=512 buttonmask=1> for active state MaskState<initializing1>. (Summary: plausible_states=[MaskState<initializing1>, MaskState<initializing0>] distance_m=[0.0365, 0.7533666666666666] match_time_m=['175us', '144us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:43,573] [play_vexpect] Waiting for any of [MaskState<initializing2>] to activate (or whether any of [MaskState<initializing1>] are still active)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,007] [play_vexpect] Applying transition: ClickTransition<initializing2->['ready0', 'ready1', 'ready2', 'ready3'] x=216 y=296 buttonmask=1> for active state MaskState<initializing2>. (Summary: plausible_states=[MaskState<initializing2>, MaskState<initializing1>] distance_m=[0.0359, 0.9961] match_time_m=['318us', '218us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,023] [play_vexpect] Waiting for any of [ready0, ready1, ready2, ready3] to activate (or whether any of [MaskState<initializing2>] are still active)\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *33 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *34 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *36 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *37 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *38 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *39 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *40 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *41 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *43 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *44 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *46 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *47 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *49 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ZYrbHK-0 | [nginx] 2018/10/17 21:51:44 [info] 64#64: *50 client closed connection while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,473] [play_vexpect] Applying transition: ClickTransition<ready1->[] x=0 y=0 buttonmask=0> for active state ready1. (Summary: plausible_states=[ready0, ready1, ready2, ready3, MaskState<initializing2>] distance_m=[0.31468353, 0.11631844, 0.4096016, 0.039567132, 0.9969333333333333] match_time_m=['201us', '115us', '108us', '72us', '189us'])\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,474] [play_vexpect] Reaching start state: ready1\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,474] [play_vexpect] vexpect macro complete in 13.631030s\n",
      "universe-ds3ZS4-0 | [tigervnc] \n",
      "universe-ds3ZS4-0 | [tigervnc] Wed Oct 17 21:51:44 2018\n",
      "universe-ds3ZS4-0 | [tigervnc]  Connections: closed: 127.0.0.1::50596 (Clean disconnection)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager: Framebuffer updates: 211\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:   ZRLE:\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Solid: 39 rects, 1.63557 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:            3.54883 KiB (1:1800.42 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Bitmap RLE: 81 rects, 1.22169 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                 158.697 KiB (1:30.0772 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Indexed RLE: 143 rects, 1.71577 Mpixels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                  501.774 KiB (1:13.3604 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:     Full Colour: 227 rects, 8.92633 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:                  25.5503 MiB (1:1.33281 ratio)\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:   Total: 490 rects, 13.4994 Mpixels\n",
      "universe-ds3ZS4-0 | [tigervnc]  EncodeManager:          26.1988 MiB (1:1.9658 ratio)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,791] [INFO:root] [EnvStatus] Changing env_state: resetting (env_id=flashgames.DuskDrive-v0) -> running (env_id=flashgames.DuskDrive-v0) (episode_id: 7->7, fps=60)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,791] [INFO:root] [Rewarder] Unblocking since env reset finished\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,792] [INFO:root] [Rewarder] Clearing reward_parser state: env_id=flashgames.DuskDrive-v0 episode_id=6->7, env_state=running\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,792] [INFO:universe.rewarder.remote] [Rewarder] Over past 16.75s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,792] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=2388.0 episode_count=160 episode_duration=93.66\n",
      "universe-ds3ZS4-0 | 2018/10/17 21:51:44 I1017 21:51:44.794462 61 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,794] [INFO:universe.wrappers.logger] Stats for the past 18.50s: vnc_updates_ps=1.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=40915.9 vnc_pixels_ps[total]=18047.5 reward_lag=None rewarder_message_lag=None fps=5.46\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,816] [INFO:universe.pyprofile] [pyprofile] period=18.48s timers={\"rewarder.sleep\": {\"mean\": \"14.19ms\", \"calls\": 96, \"std\": \"3.94ms\"}, \"reward.parsing.gameover\": {\"mean\": \"324.85us\", \"calls\": 30, \"std\": \"200.18us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.42ms\", \"calls\": 101, \"std\": \"6.56ms\"}, \"rewarder.frame\": {\"mean\": \"17.45ms\", \"calls\": 101, \"std\": \"3.34ms\"}, \"reward.parsing.score\": {\"mean\": \"9.70ms\", \"calls\": 30, \"std\": \"8.24ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"100.87us\", \"calls\": 30, \"std\": \"53.64us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"154.55us\", \"calls\": 22, \"std\": \"115.14us\"}, \"rewarder.sleep.missed\": {\"mean\": \"15.73ms\", \"calls\": 4, \"std\": \"7.41ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"78.53us\", \"calls\": 30, \"std\": \"38.62us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"12.62ms\", \"calls\": 22, \"std\": \"6.85ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"166.22us\", \"calls\": 101, \"std\": \"224.69us\"}} counters={\"agent_conn.done\": {\"mean\": 1.0, \"calls\": 1, \"std\": 0}, \"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 2, \"std\": 0.0}, \"reward.vnc.updates.n\": {\"mean\": 0.8910891089108912, \"calls\": 101, \"std\": 6.057889054941515}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 8, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 8, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 28, \"value\": 2954.0, \"std\": 0.0}} (export_time=154.02us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:44,833] [INFO:gym_controlplane.reward.reward] First score parsed: score=592\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:45,512] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25075.4 vnc_pixels_ps[total]=185886.5 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:45,513] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"377.71us\", \"mean\": \"16.81ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"624.68us\", \"mean\": \"16.03ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"244.53us\", \"mean\": \"371.87us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"124.00us\", \"mean\": \"145.05us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4705972737064394, \"mean\": 0.32890365448504966, \"calls\": 301}} gauges={} (export_time=85.83us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:45,513] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<849 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:45,808] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 45 reward messages to agent: reward=1314.0 reward_min=-26.0 reward_max=77.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2205 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:46,828] [INFO:universe.rewarder.remote] [Rewarder] Over past 1.02s, sent 57 reward messages to agent: reward=960.0 reward_min=4.0 reward_max=59.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:49,823] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"11.21ms\", \"calls\": 271, \"std\": \"4.10ms\"}, \"reward.parsing.gameover\": {\"mean\": \"294.47us\", \"calls\": 250, \"std\": \"184.12us\"}, \"rewarder.compute_reward\": {\"mean\": \"6.53ms\", \"calls\": 290, \"std\": \"6.61ms\"}, \"rewarder.frame\": {\"mean\": \"17.36ms\", \"calls\": 290, \"std\": \"2.76ms\"}, \"reward.parsing.score\": {\"mean\": \"6.75ms\", \"calls\": 250, \"std\": \"6.56ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"104.93us\", \"calls\": 250, \"std\": \"72.52us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"108.09us\", \"calls\": 183, \"std\": \"51.32us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.81ms\", \"calls\": 19, \"std\": \"6.85ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"91.81us\", \"calls\": 250, \"std\": \"74.46us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"9.77ms\", \"calls\": 161, \"std\": \"5.65ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"147.38us\", \"calls\": 290, \"std\": \"127.08us\"}} counters={\"agent_conn.reward\": {\"mean\": 16.289655172413788, \"calls\": 145, \"std\": 15.268848662017763}, \"reward.vnc.updates.n\": {\"mean\": 0.9137931034482759, \"calls\": 290, \"std\": 0.42761439953860003}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 67, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 89, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2539.915662650601, \"calls\": 249, \"value\": 2954.0, \"std\": 673.1090215970257}} (export_time=501.16us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:49,825] [INFO:universe.rewarder.remote] [Rewarder] Over past 3.00s, sent 44 reward messages to agent: reward=88.0 reward_min=0.0 reward_max=6.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<2203 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:49,828] [INFO:universe.wrappers.logger] Stats for the past 5.03s: vnc_updates_ps=64.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=1454355.6 vnc_pixels_ps[total]=623765.5 reward_lag=None rewarder_message_lag=None fps=57.83\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:50,529] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25923.7 vnc_pixels_ps[total]=192537.5 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:50,529] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"63.57us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"633.11us\", \"mean\": \"16.01ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"586.35us\", \"mean\": \"435.86us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"538.46us\", \"mean\": \"184.13us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.46811986993139343, \"mean\": 0.3222591362126244, \"calls\": 301}} gauges={} (export_time=86.07us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:51:50,530] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:54,825] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"14.49ms\", \"calls\": 286, \"std\": \"3.33ms\"}, \"reward.parsing.gameover\": {\"mean\": \"226.44us\", \"calls\": 262, \"std\": \"201.04us\"}, \"rewarder.compute_reward\": {\"mean\": \"2.66ms\", \"calls\": 297, \"std\": \"5.17ms\"}, \"rewarder.frame\": {\"mean\": \"17.07ms\", \"calls\": 297, \"std\": \"2.07ms\"}, \"reward.parsing.score\": {\"mean\": \"2.30ms\", \"calls\": 262, \"std\": \"5.24ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"121.51us\", \"calls\": 262, \"std\": \"94.57us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"145.69us\", \"calls\": 36, \"std\": \"91.54us\"}, \"rewarder.sleep.missed\": {\"mean\": \"7.38ms\", \"calls\": 11, \"std\": \"8.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"104.58us\", \"calls\": 262, \"std\": \"115.94us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"13.51ms\", \"calls\": 36, \"std\": \"6.15ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"142.67us\", \"calls\": 297, \"std\": \"103.96us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9494949494949494, \"calls\": 297, \"std\": 0.42807876991440874}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 226, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 226, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 262, \"value\": 2954.0, \"std\": 0.0}} (export_time=103.24us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:54,826] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2131 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:54,842] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=56.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=543972.1 vnc_pixels_ps[total]=221682.3 reward_lag=None rewarder_message_lag=None fps=59.25\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:55,545] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=27677.8 vnc_pixels_ps[total]=205549.3 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:55,546] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"51.09us\", \"mean\": \"16.76ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"268.42us\", \"mean\": \"16.13ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"206.85us\", \"mean\": \"342.05us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"63.29us\", \"mean\": \"128.41us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4773960376293316, \"mean\": 0.34883720930232576, \"calls\": 301}} gauges={} (export_time=68.19us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:51:55,546] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:59,853] [INFO:universe.pyprofile] [pyprofile] period=5.03s timers={\"rewarder.sleep\": {\"mean\": \"14.26ms\", \"calls\": 290, \"std\": \"3.27ms\"}, \"reward.parsing.gameover\": {\"mean\": \"198.62us\", \"calls\": 258, \"std\": \"156.10us\"}, \"rewarder.compute_reward\": {\"mean\": \"2.78ms\", \"calls\": 297, \"std\": \"4.87ms\"}, \"rewarder.frame\": {\"mean\": \"16.94ms\", \"calls\": 297, \"std\": \"1.17ms\"}, \"reward.parsing.score\": {\"mean\": \"2.54ms\", \"calls\": 258, \"std\": \"4.93ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"102.94us\", \"calls\": 258, \"std\": \"51.34us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"124.67us\", \"calls\": 55, \"std\": \"103.98us\"}, \"rewarder.sleep.missed\": {\"mean\": \"6.28ms\", \"calls\": 7, \"std\": \"4.55ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"83.60us\", \"calls\": 258, \"std\": \"54.00us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"10.13ms\", \"calls\": 55, \"std\": \"5.54ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"152.18us\", \"calls\": 297, \"std\": \"348.83us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9124579124579125, \"calls\": 297, \"std\": 0.4098611569619252}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 203, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 203, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 258, \"value\": 2954.0, \"std\": 0.0}} (export_time=527.38us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:59,854] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.pixels': 11840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:51:59,858] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=54.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=632254.0 vnc_pixels_ps[total]=250222.2 reward_lag=None rewarder_message_lag=None fps=59.24\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:00,564] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=20.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=27512.6 vnc_pixels_ps[total]=204382.5 reward_lag=None rewarder_message_lag=None fps=60.00\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:00,565] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"607.87us\", \"mean\": \"16.84ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"720.92us\", \"mean\": \"16.05ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"352.55us\", \"mean\": \"362.85us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"269.28us\", \"mean\": \"147.19us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4752338120122916, \"mean\": 0.34219269102990024, \"calls\": 301}} gauges={} (export_time=148.53us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:00,565] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:04,854] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"14.06ms\", \"calls\": 272, \"std\": \"3.40ms\"}, \"reward.parsing.gameover\": {\"mean\": \"278.94us\", \"calls\": 240, \"std\": \"190.08us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.83ms\", \"calls\": 290, \"std\": \"7.03ms\"}, \"rewarder.frame\": {\"mean\": \"17.48ms\", \"calls\": 290, \"std\": \"3.50ms\"}, \"reward.parsing.score\": {\"mean\": \"3.72ms\", \"calls\": 240, \"std\": \"7.32ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"131.99us\", \"calls\": 240, \"std\": \"70.49us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"141.89us\", \"calls\": 54, \"std\": \"65.01us\"}, \"rewarder.sleep.missed\": {\"mean\": \"11.18ms\", \"calls\": 18, \"std\": \"9.28ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"117.55us\", \"calls\": 240, \"std\": \"71.72us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"14.23ms\", \"calls\": 54, \"std\": \"8.74ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"176.51us\", \"calls\": 290, \"std\": \"140.87us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.868965517241379, \"calls\": 290, \"std\": 0.4441885009906958}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 186, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 186, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 240, \"value\": 2954.0, \"std\": 0.0}} (export_time=148.06us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ds3ZS4-0 | [2018-10-17 21:52:04,854] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2128 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:04,871] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=50.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=603379.2 vnc_pixels_ps[total]=241095.7 reward_lag=None rewarder_message_lag=None fps=57.87\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:05,579] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25619.8 vnc_pixels_ps[total]=190229.4 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:05,580] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"134.56us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"415.33us\", \"mean\": \"16.00ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"277.33us\", \"mean\": \"429.60us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"167.78us\", \"mean\": \"167.27us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4705972737064395, \"mean\": 0.3289036544850498, \"calls\": 301}} gauges={} (export_time=132.08us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:05,580] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:09,859] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"13.75ms\", \"calls\": 279, \"std\": \"3.73ms\"}, \"reward.parsing.gameover\": {\"mean\": \"276.17us\", \"calls\": 256, \"std\": \"154.27us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.77ms\", \"calls\": 293, \"std\": \"6.21ms\"}, \"rewarder.frame\": {\"mean\": \"17.18ms\", \"calls\": 293, \"std\": \"2.40ms\"}, \"reward.parsing.score\": {\"mean\": \"3.47ms\", \"calls\": 256, \"std\": \"6.42ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"139.09us\", \"calls\": 256, \"std\": \"100.19us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"138.53us\", \"calls\": 57, \"std\": \"53.51us\"}, \"rewarder.sleep.missed\": {\"mean\": \"8.63ms\", \"calls\": 14, \"std\": \"7.40ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"119.85us\", \"calls\": 256, \"std\": \"74.93us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"13.25ms\", \"calls\": 57, \"std\": \"6.77ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"162.41us\", \"calls\": 293, \"std\": \"81.60us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.907849829351536, \"calls\": 293, \"std\": 0.3904333094811047}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 199, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 199, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 256, \"value\": 2954.0, \"std\": 0.0}} (export_time=318.77us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:09,860] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2130 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:09,875] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=53.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=636702.1 vnc_pixels_ps[total]=252099.8 reward_lag=None rewarder_message_lag=None fps=58.56\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:10,596] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26130.2 vnc_pixels_ps[total]=194061.9 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:10,596] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"257.22us\", \"mean\": \"16.79ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"369.77us\", \"mean\": \"16.04ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"193.72us\", \"mean\": \"397.86us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"77.05us\", \"mean\": \"153.45us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4705972737064392, \"mean\": 0.3289036544850496, \"calls\": 301}} gauges={} (export_time=129.22us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:10,597] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<852 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:14,862] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"14.43ms\", \"calls\": 275, \"std\": \"2.89ms\"}, \"reward.parsing.gameover\": {\"mean\": \"275.88us\", \"calls\": 254, \"std\": \"151.14us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.31ms\", \"calls\": 294, \"std\": \"5.80ms\"}, \"rewarder.frame\": {\"mean\": \"17.11ms\", \"calls\": 294, \"std\": \"1.99ms\"}, \"reward.parsing.score\": {\"mean\": \"2.98ms\", \"calls\": 254, \"std\": \"5.99ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"135.69us\", \"calls\": 254, \"std\": \"53.91us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"155.36us\", \"calls\": 46, \"std\": \"79.05us\"}, \"rewarder.sleep.missed\": {\"mean\": \"5.29ms\", \"calls\": 19, \"std\": \"6.15ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"121.41us\", \"calls\": 254, \"std\": \"62.31us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"13.60ms\", \"calls\": 46, \"std\": \"6.65ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"171.25us\", \"calls\": 294, \"std\": \"171.93us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9149659863945583, \"calls\": 294, \"std\": 0.42480330585869697}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 208, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 208, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 254, \"value\": 2954.0, \"std\": 0.0}} (export_time=591.52us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:14,864] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2128 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.pixels': 1840}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:14,880] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=53.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=576396.7 vnc_pixels_ps[total]=232355.9 reward_lag=None rewarder_message_lag=None fps=58.77\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:15,614] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=25923.2 vnc_pixels_ps[total]=192534.0 reward_lag=None rewarder_message_lag=None fps=60.01\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:15,615] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"450.76us\", \"mean\": \"16.82ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"534.95us\", \"mean\": \"15.98ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"252.12us\", \"mean\": \"429.76us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"96.80us\", \"mean\": \"161.81us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.4681198699313935, \"mean\": 0.32225913621262436, \"calls\": 301}} gauges={} (export_time=272.27us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe-ZYrbHK-0 | [2018-10-17 21:52:15,616] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:19,873] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.sleep\": {\"mean\": \"13.93ms\", \"calls\": 275, \"std\": \"3.54ms\"}, \"reward.parsing.gameover\": {\"mean\": \"263.83us\", \"calls\": 247, \"std\": \"146.79us\"}, \"rewarder.compute_reward\": {\"mean\": \"3.82ms\", \"calls\": 290, \"std\": \"6.72ms\"}, \"rewarder.frame\": {\"mean\": \"17.35ms\", \"calls\": 290, \"std\": \"2.84ms\"}, \"reward.parsing.score\": {\"mean\": \"3.59ms\", \"calls\": 247, \"std\": \"6.99ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"130.53us\", \"calls\": 247, \"std\": \"57.30us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"139.36us\", \"calls\": 54, \"std\": \"56.97us\"}, \"rewarder.sleep.missed\": {\"mean\": \"10.78ms\", \"calls\": 15, \"std\": \"7.12ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"115.04us\", \"calls\": 247, \"std\": \"71.32us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"14.06ms\", \"calls\": 54, \"std\": \"8.12ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"192.18us\", \"calls\": 290, \"std\": \"230.51us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9137931034482758, \"calls\": 290, \"std\": 0.4512375431715516}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 193, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 193, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 247, \"value\": 2954.0, \"std\": 0.0}} (export_time=369.55us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:19,874] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 2, 'rewarder.profile': '<2127 bytes>', 'rewarder.vnc.updates.bytes': 41102, 'rewarder.vnc.updates.pixels': 13680}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:19,894] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=52.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=623743.3 vnc_pixels_ps[total]=247864.1 reward_lag=None rewarder_message_lag=None fps=58.07\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:20,631] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=26245.5 vnc_pixels_ps[total]=194978.8 reward_lag=None rewarder_message_lag=None fps=60.03\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:20,633] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.frame\": {\"std\": \"96.28us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"432.66us\", \"mean\": \"16.00ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"303.92us\", \"mean\": \"433.77us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"120.16us\", \"mean\": \"162.00us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.46937200333997303, \"mean\": 0.3255813953488372, \"calls\": 301}} gauges={} (export_time=273.94us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:20,634] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:24,877] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep\": {\"mean\": \"13.54ms\", \"calls\": 275, \"std\": \"4.13ms\"}, \"reward.parsing.gameover\": {\"mean\": \"261.39us\", \"calls\": 256, \"std\": \"144.33us\"}, \"rewarder.compute_reward\": {\"mean\": \"4.20ms\", \"calls\": 289, \"std\": \"7.32ms\"}, \"rewarder.frame\": {\"mean\": \"17.50ms\", \"calls\": 289, \"std\": \"3.44ms\"}, \"reward.parsing.score\": {\"mean\": \"3.89ms\", \"calls\": 256, \"std\": \"7.50ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"134.47us\", \"calls\": 256, \"std\": \"69.42us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"144.57us\", \"calls\": 59, \"std\": \"74.29us\"}, \"rewarder.sleep.missed\": {\"mean\": \"14.67ms\", \"calls\": 14, \"std\": \"6.67ms\"}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"109.43us\", \"calls\": 256, \"std\": \"54.70us\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"14.64ms\", \"calls\": 59, \"std\": \"8.54ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"180.44us\", \"calls\": 289, \"std\": \"184.05us\"}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"calls\": 1, \"std\": 0}, \"reward.vnc.updates.n\": {\"mean\": 0.9238754325259516, \"calls\": 289, \"std\": 0.3833571528630814}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"calls\": 197, \"std\": 0.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"calls\": 197, \"std\": 0.0}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"calls\": 256, \"value\": 2954.0, \"std\": 0.0}} (export_time=169.28us)\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:24,877] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<2130 bytes>', 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.pixels': 10000}\n",
      "universe-ds3ZS4-0 | [2018-10-17 21:52:24,910] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=53.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=649675.7 vnc_pixels_ps[total]=258405.5 reward_lag=None rewarder_message_lag=None fps=57.62\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:25,645] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=27177.2 vnc_pixels_ps[total]=201776.8 reward_lag=None rewarder_message_lag=None fps=60.04\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:25,646] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"222.38us\", \"mean\": \"16.78ms\", \"calls\": 301}, \"rewarder.sleep\": {\"std\": \"558.27us\", \"mean\": \"16.06ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"std\": \"361.30us\", \"mean\": \"379.12us\", \"calls\": 301}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"322.15us\", \"mean\": \"157.83us\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.47739603762933125, \"mean\": 0.3488372093023256, \"calls\": 301}} gauges={} (export_time=83.45us)\n",
      "universe-ZYrbHK-0 | [2018-10-17 21:52:25,646] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 10000, 'rewarder.vnc.updates.bytes': 1346, 'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<849 bytes>'}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('flashgames.CurveFever-v0')\n",
    "env.configure(remotes=1)  # automatically creates a local docker container\n",
    "observation_n = env.reset()\n",
    "\n",
    "while True:\n",
    "    action_n = [[('KeyEvent', 'ArrowUp', True)] for ob in observation_n]  # your agent here\n",
    "    observation_n, reward_n, done_n, info = env.step(action_n)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ,\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
